{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f76e8a7f",
   "metadata": {},
   "source": [
    "\n",
    "## Title-Lift Pipeline (Stage A + Stage B)\n",
    "\n",
    "Use this notebook with the feature-engineered dataset emitted by `bin/make_features.py` (`data/features.parquet`). It reconstructs the intrinsic exposure baseline (Stage A) and the residual title lift (Stage B) following the Weissburg et al. framing.\n",
    "\n",
    "**Expected input:** a wide table produced by the feature builder containing:\n",
    "- `post_id`, `platform`, `subreddit`, `created_timestamp`, `title`, `score` (6 h or final horizon)\n",
    "- Early snapshots: `score_5m`, `score_15m`, `score_30m`, `score_60m` (auto-added when snapshot parquet files are present)\n",
    "- Context aggregates: `hour_of_day`, `day_of_week`, `collection_type`, `author_post_count_global`, `subreddit_avg_score`, etc.\n",
    "- Title features: `title_length`, `title_words`, `has_question`, `has_numbers`, `sentiment_*`, `clickbait_*`, and related signals\n",
    "\n",
    "If any of these fields are missing, the prep cell below synthesizes reasonable fallbacks before modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94c170b",
   "metadata": {},
   "source": [
    "### Proposal Alignment Checklist\n",
    "- **Goal**: quantify Reddit/Hacker News title lift beyond early exposure by pairing an intrinsic Stage A baseline with Stage B title modeling.\n",
    "- **Collection plan**: assumes 5–minute Reddit snapshot polling (~7k stories/week) plus Hacker News REST pulls, yielding early score velocity columns (`score_5m`→`score_60m`).\n",
    "- **Modeling plan**: Stage A = exposure + context (OLS/Elastic Net), Stage B = title features (OLS, Elastic Net, LightGBM + SHAP).\n",
    "- **Success bar**: report holdout RMSE/R² shifts and ≥0.60 pairwise accuracy when ranking title variants.\n",
    "- **Deliverables**: coefficient tables, residual diagnostics, temporal/blocked robustness, pairwise lift summaries for manuscript figures.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1fe4313",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Imports ---\n",
    "import os\n",
    "from itertools import combinations\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Modeling\n",
    "import statsmodels.api as sm\n",
    "import patsy\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Display & I/O\n",
    "pd.set_option('display.max_columns', 120)\n",
    "pd.set_option('display.width', 120)\n",
    "\n",
    "DATA_FILE = Path('data/features.parquet')  # produced by bin/make_features.py\n",
    "OUTPUT_DIR = Path('outputs/title_lift')\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dee27266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: C:\\Users\\patri\\OneDrive\\Documents\\RowanMastersClassesFiles\\DataMining1\\FinalProject\n",
      "Resolved dataset path: C:\\Users\\patri\\OneDrive\\Documents\\RowanMastersClassesFiles\\DataMining1\\FinalProject\\data\\features.parquet\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Resolve project + data paths ---\n",
    "ANCHOR_FILES = ('requirements.txt', 'PROJECT_STATUS.md', '.git')\n",
    "ONE_DRIVE_HINT = Path.home() / 'OneDrive' / 'Documents' / 'RowanMastersClassesFiles' / 'DataMining1' / 'FinalProject'\n",
    "\n",
    "def find_project_root() -> Path:\n",
    "    hints = []\n",
    "    env_root = os.environ.get('TITLE_LIFT_PROJECT_ROOT')\n",
    "    if env_root:\n",
    "        hints.append(Path(env_root))\n",
    "    cwd = Path.cwd().resolve()\n",
    "    hints.extend([cwd] + list(cwd.parents))\n",
    "    if ONE_DRIVE_HINT.exists():\n",
    "        hints.append(ONE_DRIVE_HINT)\n",
    "    seen = set()\n",
    "    for hint in hints:\n",
    "        if hint is None:\n",
    "            continue\n",
    "        candidate = Path(hint).expanduser().resolve(strict=False)\n",
    "        key = str(candidate)\n",
    "        if key in seen:\n",
    "            continue\n",
    "        seen.add(key)\n",
    "        if any((candidate / anchor).exists() for anchor in ANCHOR_FILES):\n",
    "            return candidate\n",
    "    return cwd\n",
    "\n",
    "def resolve_data_path(data_file: Path, project_root: Path) -> Path:\n",
    "    env_data = os.environ.get('TITLE_LIFT_DATA_PATH')\n",
    "    if env_data:\n",
    "        env_candidate = Path(env_data).expanduser().resolve(strict=False)\n",
    "        if env_candidate.exists() and env_candidate.is_file():\n",
    "            return env_candidate\n",
    "    candidates = []\n",
    "    if data_file.is_absolute():\n",
    "        candidates.append(data_file)\n",
    "    else:\n",
    "        candidates.append(data_file)\n",
    "        if project_root.exists():\n",
    "            candidates.append(project_root / data_file)\n",
    "            if data_file.parent == Path('.'):\n",
    "                candidates.append(project_root / 'data' / data_file.name)\n",
    "        cwd = Path.cwd().resolve()\n",
    "        candidates.append(cwd / data_file)\n",
    "        if data_file.parent == Path('.'):\n",
    "            candidates.append(cwd / 'data' / data_file.name)\n",
    "        if ONE_DRIVE_HINT.exists():\n",
    "            candidates.append(ONE_DRIVE_HINT / data_file)\n",
    "    seen_paths = set()\n",
    "    for candidate in candidates:\n",
    "        if candidate is None:\n",
    "            continue\n",
    "        resolved = Path(candidate).expanduser().resolve(strict=False)\n",
    "        key = str(resolved)\n",
    "        if key in seen_paths:\n",
    "            continue\n",
    "        seen_paths.add(key)\n",
    "        if resolved.exists() and resolved.is_file():\n",
    "            return resolved\n",
    "    if project_root.exists():\n",
    "        matches = list(project_root.glob(f'**/{data_file.name}'))\n",
    "        for match in matches:\n",
    "            if match.is_file():\n",
    "                return match.resolve(strict=False)\n",
    "    raise FileNotFoundError(f'Cannot locate dataset for {data_file}')\n",
    "\n",
    "PROJECT_ROOT = find_project_root()\n",
    "INPUT_PATH = resolve_data_path(DATA_FILE, PROJECT_ROOT)\n",
    "print('Project root:', PROJECT_ROOT)\n",
    "print('Resolved dataset path:', INPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cee85533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: (13395, 90) from C:\\Users\\patri\\OneDrive\\Documents\\RowanMastersClassesFiles\\DataMining1\\FinalProject\\data\\features.parquet\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>platform</th>\n",
       "      <th>post_id</th>\n",
       "      <th>title</th>\n",
       "      <th>created_timestamp</th>\n",
       "      <th>score</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>author_hash</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>is_self_post</th>\n",
       "      <th>url</th>\n",
       "      <th>domain</th>\n",
       "      <th>text_content</th>\n",
       "      <th>is_nsfw</th>\n",
       "      <th>is_spoiler</th>\n",
       "      <th>is_stickied</th>\n",
       "      <th>collection_type</th>\n",
       "      <th>collection_run_id</th>\n",
       "      <th>ingested_timestamp</th>\n",
       "      <th>collection_type_detail</th>\n",
       "      <th>is_new_collection</th>\n",
       "      <th>subreddit_avg_score</th>\n",
       "      <th>subreddit_median_score</th>\n",
       "      <th>subreddit_post_count_global</th>\n",
       "      <th>subreddit_score_std</th>\n",
       "      <th>author_avg_score</th>\n",
       "      <th>author_post_count_global</th>\n",
       "      <th>title_length</th>\n",
       "      <th>title_words</th>\n",
       "      <th>title_chars_per_word</th>\n",
       "      <th>has_question</th>\n",
       "      <th>has_exclamation</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>all_caps_words</th>\n",
       "      <th>capitalization_ratio</th>\n",
       "      <th>number_count</th>\n",
       "      <th>has_numbers</th>\n",
       "      <th>sentiment_compound</th>\n",
       "      <th>sentiment_positive</th>\n",
       "      <th>sentiment_negative</th>\n",
       "      <th>sentiment_neutral</th>\n",
       "      <th>flesch_kincaid_grade</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>type_token_ratio</th>\n",
       "      <th>clickbait_keywords</th>\n",
       "      <th>clickbait_patterns</th>\n",
       "      <th>has_clickbait</th>\n",
       "      <th>person_entities</th>\n",
       "      <th>org_entities</th>\n",
       "      <th>date_entities</th>\n",
       "      <th>total_entities</th>\n",
       "      <th>hour_of_day</th>\n",
       "      <th>is_morning</th>\n",
       "      <th>is_afternoon</th>\n",
       "      <th>is_evening</th>\n",
       "      <th>is_night</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>is_monday</th>\n",
       "      <th>is_friday</th>\n",
       "      <th>age_hours</th>\n",
       "      <th>is_very_new</th>\n",
       "      <th>is_recent</th>\n",
       "      <th>is_old</th>\n",
       "      <th>log_age_hours</th>\n",
       "      <th>hour_sin</th>\n",
       "      <th>hour_cos</th>\n",
       "      <th>is_text_post</th>\n",
       "      <th>is_image_post</th>\n",
       "      <th>is_news_post</th>\n",
       "      <th>is_external_link</th>\n",
       "      <th>has_author</th>\n",
       "      <th>author_post_count</th>\n",
       "      <th>is_frequent_poster</th>\n",
       "      <th>author_post_count_log</th>\n",
       "      <th>subreddit_post_count</th>\n",
       "      <th>score_at_5min</th>\n",
       "      <th>score_at_15min</th>\n",
       "      <th>growth_rate_15min</th>\n",
       "      <th>score_at_30min</th>\n",
       "      <th>growth_rate_30min</th>\n",
       "      <th>score_at_60min</th>\n",
       "      <th>growth_rate_60min</th>\n",
       "      <th>early_momentum</th>\n",
       "      <th>sustained_growth</th>\n",
       "      <th>score_5m</th>\n",
       "      <th>score_15m</th>\n",
       "      <th>score_30m</th>\n",
       "      <th>score_60m</th>\n",
       "      <th>velocity_5_to_30m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>reddit</td>\n",
       "      <td>1oc03pf</td>\n",
       "      <td>Tron: Ares is on track to become a box office ...</td>\n",
       "      <td>1.761011e+09</td>\n",
       "      <td>1946</td>\n",
       "      <td>231</td>\n",
       "      <td>b31aed41</td>\n",
       "      <td>0.98</td>\n",
       "      <td>business</td>\n",
       "      <td>False</td>\n",
       "      <td>https://www.gamesradar.com/entertainment/sci-f...</td>\n",
       "      <td>gamesradar.com</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>74.680498</td>\n",
       "      <td>1.0</td>\n",
       "      <td>482</td>\n",
       "      <td>249.604689</td>\n",
       "      <td>936.185185</td>\n",
       "      <td>243</td>\n",
       "      <td>112</td>\n",
       "      <td>22</td>\n",
       "      <td>5.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.035294</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.7096</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.772</td>\n",
       "      <td>9.080909</td>\n",
       "      <td>4.136364</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>690.806314</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.539306</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>243</td>\n",
       "      <td>1</td>\n",
       "      <td>5.497168</td>\n",
       "      <td>482</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999489</td>\n",
       "      <td>0</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>reddit</td>\n",
       "      <td>1nxj54x</td>\n",
       "      <td>Costco to sell Ozempic and Wegovy at a large d...</td>\n",
       "      <td>1.759548e+09</td>\n",
       "      <td>1916</td>\n",
       "      <td>150</td>\n",
       "      <td>b31aed41</td>\n",
       "      <td>0.98</td>\n",
       "      <td>business</td>\n",
       "      <td>False</td>\n",
       "      <td>https://www.nbcnews.com/news/amp/rcna235471</td>\n",
       "      <td>nbcnews.com</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>74.680498</td>\n",
       "      <td>1.0</td>\n",
       "      <td>482</td>\n",
       "      <td>249.604689</td>\n",
       "      <td>936.185185</td>\n",
       "      <td>243</td>\n",
       "      <td>82</td>\n",
       "      <td>14</td>\n",
       "      <td>5.857143</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>8.412857</td>\n",
       "      <td>4.928571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1097.207703</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.001435</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>243</td>\n",
       "      <td>1</td>\n",
       "      <td>5.497168</td>\n",
       "      <td>482</td>\n",
       "      <td>1916.0</td>\n",
       "      <td>1916.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1916.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1916.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999478</td>\n",
       "      <td>0</td>\n",
       "      <td>1916.0</td>\n",
       "      <td>1916.0</td>\n",
       "      <td>1916.0</td>\n",
       "      <td>1916.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>reddit</td>\n",
       "      <td>1ojbmz0</td>\n",
       "      <td>Kraft Heinz CEO Warns of Worst Consumer Sentim...</td>\n",
       "      <td>1.761761e+09</td>\n",
       "      <td>1781</td>\n",
       "      <td>205</td>\n",
       "      <td>b4d96c28</td>\n",
       "      <td>0.98</td>\n",
       "      <td>business</td>\n",
       "      <td>False</td>\n",
       "      <td>https://www.bloomberg.com/news/articles/2025-1...</td>\n",
       "      <td>bloomberg.com</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>74.680498</td>\n",
       "      <td>1.0</td>\n",
       "      <td>482</td>\n",
       "      <td>249.604689</td>\n",
       "      <td>656.666667</td>\n",
       "      <td>3</td>\n",
       "      <td>58</td>\n",
       "      <td>10</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.204082</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.6705</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.407</td>\n",
       "      <td>0.593</td>\n",
       "      <td>4.830000</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>482.463814</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.180976</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>482</td>\n",
       "      <td>1827.0</td>\n",
       "      <td>1827.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1827.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1827.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999453</td>\n",
       "      <td>0</td>\n",
       "      <td>1827.0</td>\n",
       "      <td>1827.0</td>\n",
       "      <td>1827.0</td>\n",
       "      <td>1827.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  platform  post_id                                              title  created_timestamp  score  comment_count  \\\n",
       "0   reddit  1oc03pf  Tron: Ares is on track to become a box office ...       1.761011e+09   1946            231   \n",
       "1   reddit  1nxj54x  Costco to sell Ozempic and Wegovy at a large d...       1.759548e+09   1916            150   \n",
       "2   reddit  1ojbmz0  Kraft Heinz CEO Warns of Worst Consumer Sentim...       1.761761e+09   1781            205   \n",
       "\n",
       "  author_hash  upvote_ratio subreddit  is_self_post                                                url  \\\n",
       "0    b31aed41          0.98  business         False  https://www.gamesradar.com/entertainment/sci-f...   \n",
       "1    b31aed41          0.98  business         False        https://www.nbcnews.com/news/amp/rcna235471   \n",
       "2    b4d96c28          0.98  business         False  https://www.bloomberg.com/news/articles/2025-1...   \n",
       "\n",
       "           domain text_content  is_nsfw  is_spoiler  is_stickied collection_type collection_run_id  \\\n",
       "0  gamesradar.com                 False       False        False            None              None   \n",
       "1     nbcnews.com                 False       False        False            None              None   \n",
       "2   bloomberg.com                 False       False        False            None              None   \n",
       "\n",
       "   ingested_timestamp collection_type_detail  is_new_collection  subreddit_avg_score  subreddit_median_score  \\\n",
       "0                 NaN                   None                  0            74.680498                     1.0   \n",
       "1                 NaN                   None                  0            74.680498                     1.0   \n",
       "2                 NaN                   None                  0            74.680498                     1.0   \n",
       "\n",
       "   subreddit_post_count_global  subreddit_score_std  author_avg_score  author_post_count_global  title_length  \\\n",
       "0                          482           249.604689        936.185185                       243           112   \n",
       "1                          482           249.604689        936.185185                       243            82   \n",
       "2                          482           249.604689        656.666667                         3            58   \n",
       "\n",
       "   title_words  title_chars_per_word  has_question  has_exclamation  punctuation_count  all_caps_words  \\\n",
       "0           22              5.090909             0                0                  3               0   \n",
       "1           14              5.857143             0                0                  0               0   \n",
       "2           10              5.800000             0                0                  0               1   \n",
       "\n",
       "   capitalization_ratio  number_count  has_numbers  sentiment_compound  sentiment_positive  sentiment_negative  \\\n",
       "0              0.035294             1            1             -0.7096                 0.0               0.228   \n",
       "1              0.043478             0            0              0.0000                 0.0               0.000   \n",
       "2              0.204082             0            0             -0.6705                 0.0               0.407   \n",
       "\n",
       "   sentiment_neutral  flesch_kincaid_grade  avg_word_length  type_token_ratio  clickbait_keywords  clickbait_patterns  \\\n",
       "0              0.772              9.080909         4.136364          0.863636                   0                   0   \n",
       "1              1.000              8.412857         4.928571          1.000000                   0                   0   \n",
       "2              0.593              4.830000         4.900000          1.000000                   0                   0   \n",
       "\n",
       "   has_clickbait  person_entities  org_entities  date_entities  total_entities  hour_of_day  is_morning  is_afternoon  \\\n",
       "0              0                0             1              0               1            1           0             0   \n",
       "1              0                0             3              0               3            3           0             0   \n",
       "2              0                1             2              0               3           17           0             1   \n",
       "\n",
       "   is_evening  is_night  day_of_week  is_weekend  is_monday  is_friday    age_hours  is_very_new  is_recent  is_old  \\\n",
       "0           0         1            1           0          0          0   690.806314            0          0       1   \n",
       "1           0         1            5           1          0          0  1097.207703            0          0       1   \n",
       "2           0         0            2           0          0          0   482.463814            0          0       1   \n",
       "\n",
       "   log_age_hours  hour_sin  hour_cos  is_text_post  is_image_post  is_news_post  is_external_link  has_author  \\\n",
       "0       6.539306  0.258819  0.965926             0              0             0                 1           1   \n",
       "1       7.001435  0.707107  0.707107             0              0             0                 1           1   \n",
       "2       6.180976 -0.965926 -0.258819             0              0             0                 1           1   \n",
       "\n",
       "   author_post_count  is_frequent_poster  author_post_count_log  subreddit_post_count  score_at_5min  score_at_15min  \\\n",
       "0                243                   1               5.497168                   482         1955.0          1955.0   \n",
       "1                243                   1               5.497168                   482         1916.0          1916.0   \n",
       "2                  3                   0               1.386294                   482         1827.0          1827.0   \n",
       "\n",
       "   growth_rate_15min  score_at_30min  growth_rate_30min  score_at_60min  growth_rate_60min  early_momentum  \\\n",
       "0                0.0          1955.0                0.0          1955.0                0.0        0.999489   \n",
       "1                0.0          1916.0                0.0          1916.0                0.0        0.999478   \n",
       "2                0.0          1827.0                0.0          1827.0                0.0        0.999453   \n",
       "\n",
       "   sustained_growth  score_5m  score_15m  score_30m  score_60m  velocity_5_to_30m  \n",
       "0                 0    1955.0     1955.0     1955.0     1955.0                0.0  \n",
       "1                 0    1916.0     1916.0     1916.0     1916.0                0.0  \n",
       "2                 0    1827.0     1827.0     1827.0     1827.0                0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# --- Load data ---\n",
    "def load_any(path: Path) -> pd.DataFrame:\n",
    "    if path.suffix and path.exists():\n",
    "        if path.suffix == '.parquet':\n",
    "            return pd.read_parquet(path)\n",
    "        if path.suffix == '.csv':\n",
    "            return pd.read_csv(path)\n",
    "    for suffix in ('.parquet', '.csv'):\n",
    "        candidate = path.with_suffix(suffix)\n",
    "        if candidate.exists():\n",
    "            return pd.read_parquet(candidate) if suffix == '.parquet' else pd.read_csv(candidate)\n",
    "    raise FileNotFoundError(f'Cannot locate dataset for {path}')\n",
    "\n",
    "df = load_any(INPUT_PATH)\n",
    "print('Loaded:', df.shape, 'from', INPUT_PATH)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa0d5392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared: (13395, 95) Outcome: score_60m Early: score_5m\n",
      "   score_5m  score_60m         y         E  hour_of_day  day_of_week  is_self  is_image\n",
      "0    1955.0     1955.0  7.578657  7.578657            1            1        0         0\n",
      "1    1916.0     1916.0  7.558517  7.558517            3            5        0         0\n",
      "2    1827.0     1827.0  7.510978  7.510978           17            2        0         0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Hygiene ---\n",
    "df = df.copy()\n",
    "\n",
    "# Ensure key string columns exist and are clean\n",
    "for col in ['title', 'domain', 'subreddit', 'platform', 'collection_type']:\n",
    "    if col not in df.columns:\n",
    "        df[col] = '' if col != 'platform' else 'unknown'\n",
    "    fill_value = 'unknown' if col in ['platform', 'collection_type'] else ''\n",
    "    df[col] = df[col].fillna(fill_value).astype(str)\n",
    "\n",
    "# Harmonize timestamps to derive hour/day if needed\n",
    "created_dt = None\n",
    "if 'created_timestamp' in df.columns:\n",
    "    created_dt = pd.to_datetime(df['created_timestamp'], utc=True, errors='coerce')\n",
    "elif 'created_utc' in df.columns:\n",
    "    created_dt = pd.to_datetime(df['created_utc'], unit='s', utc=True, errors='coerce')\n",
    "if created_dt is not None:\n",
    "    df['created_dt'] = created_dt\n",
    "    if 'hour_of_day' not in df.columns:\n",
    "        df['hour_of_day'] = created_dt.dt.hour\n",
    "    if 'day_of_week' not in df.columns:\n",
    "        df['day_of_week'] = created_dt.dt.weekday\n",
    "\n",
    "# Determine early / outcome columns from available signals\n",
    "EARLY_CANDIDATES = [col for col in ['score_5m', 'score_15m', 'score_30m', 'score_60m'] if col in df.columns]\n",
    "if not EARLY_CANDIDATES:\n",
    "    raise ValueError('Feature dataset needs at least one early score column (score_5m/15m/30m/60m).')\n",
    "EARLY_COL = EARLY_CANDIDATES[0]\n",
    "ALT_EARLY_COLS = EARLY_CANDIDATES[1:]\n",
    "\n",
    "OUTCOME_CANDIDATES = ['score_60m', 'score', 'score_final']\n",
    "OUTCOME_COL = next((col for col in OUTCOME_CANDIDATES if col in df.columns), None)\n",
    "if OUTCOME_COL is None:\n",
    "    raise ValueError('Outcome column not found; expected one of score_60m, score, score_final.')\n",
    "\n",
    "# Fill aggregate features if feature builder was skipped\n",
    "if 'subreddit_avg_score' not in df.columns:\n",
    "    df['subreddit_avg_score'] = df.groupby('subreddit')[OUTCOME_COL].transform('mean')\n",
    "df['subreddit_avg_score'] = df['subreddit_avg_score'].fillna(df[OUTCOME_COL].median())\n",
    "\n",
    "if 'subreddit_score_std' not in df.columns:\n",
    "    df['subreddit_score_std'] = df.groupby('subreddit')[OUTCOME_COL].transform('std')\n",
    "df['subreddit_score_std'] = df['subreddit_score_std'].fillna(0.0)\n",
    "\n",
    "if 'author_post_count_global' not in df.columns:\n",
    "    if 'author_hash' in df.columns:\n",
    "        df['author_post_count_global'] = df.groupby('author_hash')['author_hash'].transform('count')\n",
    "    else:\n",
    "        df['author_post_count_global'] = 0.0\n",
    "df['author_post_count_global'] = df['author_post_count_global'].fillna(0.0).astype(float)\n",
    "\n",
    "if 'author_avg_score' not in df.columns:\n",
    "    if 'author_hash' in df.columns:\n",
    "        df['author_avg_score'] = df.groupby('author_hash')[OUTCOME_COL].transform('mean')\n",
    "    else:\n",
    "        df['author_avg_score'] = df[OUTCOME_COL].median()\n",
    "df['author_avg_score'] = df['author_avg_score'].fillna(df['author_avg_score'].median()).astype(float)\n",
    "\n",
    "# Binary flags\n",
    "df['is_self'] = df.get('is_self_post', df.get('is_self', 0)).fillna(0).astype(int)\n",
    "df['is_image'] = df['domain'].str.lower().isin({'i.redd.it', 'i.imgur.com', 'imgur.com'}).astype(int)\n",
    "df['is_new_collection'] = df.get('is_new_collection', 0).fillna(0).astype(int)\n",
    "\n",
    "# Drop rows missing required signals\n",
    "required_cols = ['subreddit', 'hour_of_day', 'day_of_week', EARLY_COL, OUTCOME_COL]\n",
    "df = df.dropna(subset=required_cols)\n",
    "\n",
    "# Stabilize log scale targets\n",
    "df['y'] = np.log1p(df[OUTCOME_COL].astype(float).clip(lower=0))\n",
    "df['E'] = np.log1p(df[EARLY_COL].astype(float).clip(lower=0))\n",
    "\n",
    "print('Prepared:', df.shape, 'Outcome:', OUTCOME_COL, 'Early:', EARLY_COL)\n",
    "preview_cols = [EARLY_COL, OUTCOME_COL, 'y', 'E', 'hour_of_day', 'day_of_week', 'is_self', 'is_image']\n",
    "print(df[preview_cols].head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a8dcc1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679008b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_profile = {\n",
    "    \"rows\": int(len(df)),\n",
    "    \"platforms\": df['platform'].nunique() if 'platform' in df.columns else 0,\n",
    "    \"subreddits\": df['subreddit'].nunique() if 'subreddit' in df.columns else 0,\n",
    "    \"snapshot_columns\": {col: (col in df.columns) for col in ['score_5m', 'score_15m', 'score_30m', 'score_60m']}\n",
    "}\n",
    "valid_times = df['created_dt'].dropna() if 'created_dt' in df.columns else pd.Series([], dtype='datetime64[ns]')\n",
    "if not valid_times.empty:\n",
    "    dataset_profile[\"time_range\"] = (\n",
    "        valid_times.min().strftime('%Y-%m-%d %H:%M'),\n",
    "        valid_times.max().strftime('%Y-%m-%d %H:%M')\n",
    "    )\n",
    "else:\n",
    "    dataset_profile[\"time_range\"] = (None, None)\n",
    "\n",
    "print(\"Total posts:\", dataset_profile[\"rows\"])\n",
    "if dataset_profile[\"platforms\"]:\n",
    "    print(\"Platforms (top 5 counts):\")\n",
    "    display(df['platform'].value_counts().head(5))\n",
    "if dataset_profile[\"subreddits\"]:\n",
    "    print(\"Subreddits represented:\", dataset_profile[\"subreddits\"])\n",
    "print(\"Snapshot columns present:\", dataset_profile[\"snapshot_columns\"])\n",
    "if all(dataset_profile[\"time_range\"]):\n",
    "    print(\"Collection window:\", \" → \".join(dataset_profile[\"time_range\"]))\n",
    "\n",
    "sentiment_cols = [col for col in df.columns if col.startswith('sentiment_')]\n",
    "clickbait_cols = [col for col in df.columns if col.startswith('clickbait_') or col == 'has_clickbait']\n",
    "feature_cols = sentiment_cols + clickbait_cols\n",
    "if feature_cols:\n",
    "    summary_table = df[feature_cols].describe().T[['mean', 'std', 'min', 'max']].round(3)\n",
    "    print(\"Sentiment/Clickbait feature summary:\")\n",
    "    display(summary_table)\n",
    "else:\n",
    "    print(\"Sentiment and clickbait features unavailable; rerun feature engineering if needed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcae3889",
   "metadata": {},
   "source": [
    "\n",
    "## Stage A — Intrinsic (Exposure-Adjusted) Baseline\n",
    "\n",
    "We fit a model that predicts the stabilized outcome `y = log(1 + score_6hr)` from **early exposure** `E = log(1 + score_5m)` and **context** (hour, day, subreddit, content-type, author frequency).\n",
    "\n",
    "> No title features here — by design — so title effects are not absorbed into the baseline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b18d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Stage A: Intrinsic baseline ---\n",
    "if 'y' not in df.columns or 'E' not in df.columns:\n",
    "    raise ValueError('Stage A requires the stabilized outcome `y` and exposure `E`; run the prep cell first.')\n",
    "\n",
    "categorical_terms = []\n",
    "if 'platform' in df.columns:\n",
    "    categorical_terms.append('platform')\n",
    "if 'collection_type' in df.columns and df['collection_type'].nunique() > 1:\n",
    "    categorical_terms.append('collection_type')\n",
    "if 'subreddit' in df.columns and df['subreddit'].nunique() > 1:\n",
    "    categorical_terms.append('subreddit')\n",
    "if 'hour_of_day' in df.columns:\n",
    "    categorical_terms.append('hour_of_day')\n",
    "if 'day_of_week' in df.columns:\n",
    "    categorical_terms.append('day_of_week')\n",
    "\n",
    "numeric_candidates = [\n",
    "    'is_self',\n",
    "    'is_image',\n",
    "    'is_new_collection',\n",
    "    'author_post_count_global',\n",
    "    'author_avg_score',\n",
    "    'subreddit_avg_score',\n",
    "    'subreddit_score_std'\n",
    " ]\n",
    "numeric_terms = []\n",
    "for candidate in numeric_candidates:\n",
    "    if candidate in df.columns:\n",
    "        df[candidate] = pd.to_numeric(df[candidate], errors='coerce')\n",
    "        numeric_terms.append(candidate)\n",
    "\n",
    "stage_a_terms = ['E'] + [f'C({col})' for col in categorical_terms] + numeric_terms\n",
    "if len(stage_a_terms) == 1:\n",
    "    print('Warning: Stage A baseline only has the exposure term; context columns were not found.')\n",
    "\n",
    "stage_a_model_cols = ['y', 'E'] + categorical_terms + numeric_terms\n",
    "model_df = df.loc[:, stage_a_model_cols].replace([np.inf, -np.inf], np.nan)\n",
    "valid_index = model_df.dropna().index\n",
    "dropped = len(model_df) - len(valid_index)\n",
    "if len(valid_index) == 0:\n",
    "    raise ValueError('Stage A cannot fit because no rows remain after dropping missing exposure/context values.')\n",
    "if dropped > 0:\n",
    "    print(f'Dropped {dropped} rows before Stage A fit due to missing exposure/context fields.')\n",
    "\n",
    "df = df.loc[valid_index].copy()\n",
    "model_df = df.loc[:, stage_a_model_cols].copy()\n",
    "for col in categorical_terms:\n",
    "    model_df[col] = model_df[col].astype('category')\n",
    "\n",
    "formula_A = 'y ~ ' + ' + '.join(stage_a_terms)\n",
    "print('Stage A formula:', formula_A)\n",
    "\n",
    "y_A, X_A = patsy.dmatrices(formula_A, data=model_df, return_type='dataframe')\n",
    "ols_A = sm.OLS(y_A, X_A).fit()\n",
    "print(ols_A.summary().as_text()[:2000])\n",
    "\n",
    "df['yhat_A'] = ols_A.predict(X_A)\n",
    "df['R'] = df['y'] - df['yhat_A']\n",
    "stage_a_coefficients = (\n",
    "    pd.DataFrame({\n",
    "        'feature': ols_A.model.exog_names,\n",
    "        'coefficient': ols_A.params.to_numpy(),\n",
    "        'std_error': ols_A.bse.to_numpy()\n",
    "    })\n",
    "    .assign(abs_coef=lambda d: d['coefficient'].abs())\n",
    "    .sort_values('abs_coef', ascending=False)\n",
    " )\n",
    "print(f'Stage A fit complete on {len(df):,} rows with {len(ols_A.params)} parameters.')\n",
    "\n",
    "if 'hour_of_day' in df.columns:\n",
    "    calibration = df.groupby('hour_of_day')['R'].agg(['mean', 'count']).reset_index()\n",
    "    print('\\nResidual calibration by hour_of_day (mean, count):')\n",
    "    print(calibration.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06feb21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot residual distribution\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.hist(df['R'].dropna(), bins=50)\n",
    "plt.title('Stage A Residuals (R = y - yhat_A)')\n",
    "plt.xlabel('Residual')\n",
    "plt.ylabel('Count')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6880ad1",
   "metadata": {},
   "source": [
    "### Stage A Key Drivers\n",
    "Quantify which contextual and exposure features contribute most to the intrinsic-quality baseline before titles are introduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857a1770",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_df = stage_a_coefficients.copy()\n",
    "if 'feature' in display_df.columns:\n",
    "    display_df = display_df[display_df['feature'] != 'Intercept']\n",
    "else:\n",
    "    raise ValueError('stage_a_coefficients is missing the \"feature\" column; rerun the Stage A fit cell.')\n",
    "\n",
    "display_df = display_df.assign(abs_coef=lambda d: d['coefficient'].abs()).sort_values('abs_coef', ascending=False)\n",
    "print('Top Stage A contributors (absolute magnitude):')\n",
    "display(display_df.head(12))\n",
    "print('\\nMost negative Stage A coefficients:')\n",
    "display(display_df.sort_values('coefficient').head(6)[['feature', 'coefficient', 'std_error']])\n",
    "print('\\nMost positive Stage A coefficients:')\n",
    "display(display_df.sort_values('coefficient', ascending=False).head(6)[['feature', 'coefficient', 'std_error']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3a999f",
   "metadata": {},
   "source": [
    "\n",
    "## Stage B — Residual Title Lift\n",
    "\n",
    "We regress residuals `R` on **title features** (and optionally feature×subreddit interactions) to quantify marginal title effects beyond exposure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc6498a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage B — residual title lift (OLS)\n",
    "from datetime import datetime\n",
    "\n",
    "title_feature_candidates = [\n",
    "    'title_length','title_words','title_chars_per_word','has_question','has_numbers',\n",
    "    'has_exclamation','capitalization_ratio','all_caps_words','number_count',\n",
    "    'sentiment_compound','sentiment_positive','sentiment_negative','sentiment_neutral',\n",
    "    'clickbait_patterns','clickbait_keywords','has_clickbait'\n",
    "]\n",
    "TITLE_FEATURES = [col for col in title_feature_candidates if col in df.columns]\n",
    "if not TITLE_FEATURES:\n",
    "    raise ValueError('No title features detected; ensure feature engineering step ran.')\n",
    "formula_B = 'R ~ ' + ' + '.join(TITLE_FEATURES)\n",
    "print('Stage B formula:', formula_B)\n",
    "\n",
    "y_B, X_B = patsy.dmatrices(formula_B, data=df, return_type='dataframe')\n",
    "ols_B = sm.OLS(y_B, X_B).fit()\n",
    "print(ols_B.summary().as_text()[:2000])\n",
    "\n",
    "df['Rhat_B'] = ols_B.predict(X_B)\n",
    "df['title_lift_component'] = df['Rhat_B']\n",
    "\n",
    "interaction_feature = 'has_clickbait' if 'has_clickbait' in TITLE_FEATURES else ('has_numbers' if 'has_numbers' in TITLE_FEATURES else None)\n",
    "if interaction_feature and 'subreddit' in df.columns and df['subreddit'].nunique() > 1:\n",
    "    formula_Bx = formula_B + f' + C(subreddit):{interaction_feature}'\n",
    "    y_Bx, X_Bx = patsy.dmatrices(formula_Bx, data=df, return_type='dataframe')\n",
    "    ols_Bx = sm.OLS(y_Bx, X_Bx).fit()\n",
    "    print('\\nWith subreddit interaction (truncated):\\n', ols_Bx.summary().as_text()[:2000])\n",
    "else:\n",
    "    ols_Bx = None\n",
    "\n",
    "coef_B = ols_B.params.rename('coef').to_frame()\n",
    "coef_B['se'] = ols_B.bse\n",
    "coef_path = OUTPUT_DIR / 'stageB_coefs.csv'\n",
    "\n",
    "try:\n",
    "    coef_B.to_csv(coef_path)\n",
    "    stage_b_coef_path = coef_path\n",
    "    print('Saved Stage B coefficients to', coef_path)\n",
    "except PermissionError:\n",
    "    fallback_path = coef_path.with_name(f\"{coef_path.stem}_{datetime.now().strftime('%Y%m%d_%H%M%S')}{coef_path.suffix}\")\n",
    "    # Fall back when the canonical CSV is locked (e.g., open in Excel).\n",
    "    coef_B.to_csv(fallback_path)\n",
    "    stage_b_coef_path = fallback_path\n",
    "    print(f'Permission denied writing {coef_path}; saved Stage B coefficients to {fallback_path} instead.')\n",
    "\n",
    "coef_B.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5587bc5e",
   "metadata": {},
   "source": [
    "## Stage B Variant Check — Mean-Centered Title Features\n",
    "We re-estimate Stage B after subtracting each title feature’s mean. This sets the intercept to the expected residual lift for an “average” title and lets us compare coefficients, residual fit, and downstream diagnostics against the raw (uncentered) specification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54814a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Stage B (mean-centered comparison) ---\n",
    "# Keep a separate variant with mean-centered title features to compare coefficients and fit.\n",
    "center_suffix = '_centered'\n",
    "centered_feature_map = {f'{col}{center_suffix}': df[col] - df[col].mean() for col in TITLE_FEATURES}\n",
    "df_center = df.assign(**centered_feature_map)\n",
    "\n",
    "formula_B_centered = 'R ~ ' + ' + '.join(f'{col}{center_suffix}' for col in TITLE_FEATURES)\n",
    "print('Stage B (centered) formula:', formula_B_centered)\n",
    "y_B_center, X_B_center = patsy.dmatrices(formula_B_centered, data=df_center, return_type='dataframe')\n",
    "ols_B_center = sm.OLS(y_B_center, X_B_center).fit()\n",
    "print(ols_B_center.summary().as_text()[:2000])\n",
    "\n",
    "df['Rhat_B_centered'] = ols_B_center.predict(X_B_center)\n",
    "df['title_lift_component_centered'] = df['Rhat_B_centered']\n",
    "df['stage_b_prediction_centered'] = df['yhat_A'] + df['title_lift_component_centered']\n",
    "df['stage_b_residual_centered'] = df['y'] - df['stage_b_prediction_centered']\n",
    "\n",
    "coef_B_raw = pd.DataFrame({'coef_raw': ols_B.params, 'se_raw': ols_B.bse})\n",
    "coef_B_centered = pd.DataFrame({'coef_centered': ols_B_center.params, 'se_centered': ols_B_center.bse})\n",
    "coef_B_centered.index = [idx.replace(center_suffix, '') for idx in coef_B_centered.index]\n",
    "\n",
    "comparison = (\n",
    "    coef_B_raw.join(coef_B_centered, how='outer')\n",
    "                 .assign(abs_coef_raw=lambda d: d['coef_raw'].abs(),\n",
    "                         abs_coef_centered=lambda d: d['coef_centered'].abs())\n",
    "                 .sort_index()\n",
    ")\n",
    "print('Coefficient comparison (raw vs mean-centered):')\n",
    "display(comparison.head(12))\n",
    "\n",
    "stage_b_rmse_centered = float(np.sqrt(np.mean(np.square(df['y'] - df['stage_b_prediction_centered']))))\n",
    "stage_b_mae_centered = float(np.mean(np.abs(df['y'] - df['stage_b_prediction_centered'])))\n",
    "print(f'Stage B centered RMSE (log space): {stage_b_rmse_centered:.4f}')\n",
    "print(f'Stage B centered MAE (log space): {stage_b_mae_centered:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc51757f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Stage B (Elastic Net variant) ---\n",
    "# Regress residuals on title features with ElasticNetCV to allow sparse feature selection.\n",
    "X_title = df[TITLE_FEATURES].fillna(0.0)\n",
    "y_resid = df['R']\n",
    "\n",
    "elastic_net = Pipeline([\n",
    "    ('scaler', StandardScaler(with_mean=True, with_std=True)),\n",
    "    ('model', ElasticNetCV(\n",
    "        l1_ratio=[0.1, 0.3, 0.5, 0.7, 0.9, 1.0],\n",
    "        alphas=np.logspace(-3, 1, 25),  # explicit alpha grid avoids deprecated default\n",
    "        cv=5,\n",
    "        n_jobs=None,\n",
    "        random_state=RANDOM_STATE\n",
    "    ))\n",
    "])\n",
    "elastic_net.fit(X_title, y_resid)\n",
    "\n",
    "en_model = elastic_net.named_steps['model']\n",
    "print('Elastic Net best alpha:', round(en_model.alpha_, 6))\n",
    "print('Elastic Net best l1_ratio:', round(en_model.l1_ratio_, 3))\n",
    "\n",
    "df['Rhat_B_en'] = elastic_net.predict(X_title)\n",
    "df['title_lift_component_en'] = df['Rhat_B_en']\n",
    "df['stage_b_prediction_en'] = df['yhat_A'] + df['title_lift_component_en']\n",
    "df['stage_b_residual_en'] = df['y'] - df['stage_b_prediction_en']\n",
    "\n",
    "en_coef = pd.DataFrame({\n",
    "    'feature': X_title.columns,\n",
    "    'coef': elastic_net.named_steps['model'].coef_\n",
    "}).assign(abs_coef=lambda d: d['coef'].abs()).sort_values('abs_coef', ascending=False)\n",
    "print('Top Elastic Net coefficients (abs):')\n",
    "display(en_coef.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6980b32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Stage B (LightGBM confirmation + SHAP) ---\n",
    "# Gradient boosted trees capture non-linear title effects; SHAP quantifies feature influence.\n",
    "lgb_params = dict(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.05,\n",
    "    num_leaves=31,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1\n",
    " )\n",
    "lgb_model = lgb.LGBMRegressor(**lgb_params)\n",
    "lgb_model.fit(X_title, y_resid)\n",
    "\n",
    "df['Rhat_B_lgb'] = lgb_model.predict(X_title)\n",
    "df['title_lift_component_lgb'] = df['Rhat_B_lgb']\n",
    "df['stage_b_prediction_lgb'] = df['yhat_A'] + df['title_lift_component_lgb']\n",
    "df['stage_b_residual_lgb'] = df['y'] - df['stage_b_prediction_lgb']\n",
    "\n",
    "shap_importance = None\n",
    "try:\n",
    "    import shap\n",
    "    shap_sample = X_title.sample(min(2000, len(X_title)), random_state=RANDOM_STATE)\n",
    "    explainer = shap.TreeExplainer(lgb_model)\n",
    "    shap_values = explainer.shap_values(shap_sample)\n",
    "    if isinstance(shap_values, list):\n",
    "        shap_values = shap_values[0]\n",
    "    shap_importance = pd.DataFrame({\n",
    "        'feature': shap_sample.columns,\n",
    "        'mean_abs_shap': np.abs(shap_values).mean(axis=0)\n",
    "    }).sort_values('mean_abs_shap', ascending=False)\n",
    "    print('Top SHAP contributions (LightGBM):')\n",
    "    display(shap_importance.head(10))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(7, 4))\n",
    "    top_shap = shap_importance.head(10).sort_values('mean_abs_shap')\n",
    "    ax.barh(top_shap['feature'], top_shap['mean_abs_shap'], color='#6a3d9a')\n",
    "    ax.set_xlabel('Mean |SHAP value| (log residual space)')\n",
    "    ax.set_title('LightGBM title feature influence (top 10)')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "except ImportError:\n",
    "    print('SHAP is not installed; falling back to LightGBM gain-based importance. Run \"pip install shap\" if you want SHAP plots.')\n",
    "\n",
    "if shap_importance is None:\n",
    "    booster = lgb_model.booster_ if hasattr(lgb_model, 'booster_') else lgb_model.booster\n",
    "    gain_importance = pd.DataFrame({\n",
    "        'feature': X_title.columns,\n",
    "        'gain_importance': booster.feature_importance(importance_type='gain'),\n",
    "        'split_importance': booster.feature_importance(importance_type='split')\n",
    "    }).sort_values('gain_importance', ascending=False)\n",
    "    print('LightGBM gain-based feature importance (fallback):')\n",
    "    display(gain_importance.head(10))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(7, 4))\n",
    "    top_gain = gain_importance.head(10).sort_values('gain_importance')\n",
    "    ax.barh(top_gain['feature'], top_gain['gain_importance'], color='#2ca02c')\n",
    "    ax.set_xlabel('Gain importance')\n",
    "    ax.set_title('LightGBM title feature importance (gain, top 10)')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18fb4df",
   "metadata": {},
   "source": [
    "\n",
    "### Post-Run Diagnostics\n",
    "\n",
    "The cells below summarize Stage A and Stage B behavior, highlight the most influential title features, visualize residual structure, and evaluate pairwise ranking lift after incorporating the title model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684c87a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Stage-level diagnostics ---\n",
    "df['stage_b_prediction'] = df['yhat_A'] + df['title_lift_component']\n",
    "df['stage_b_residual'] = df['y'] - df['stage_b_prediction']\n",
    "df['stage_b_gain'] = df['stage_b_prediction'] - df['yhat_A']\n",
    "df['abs_residual'] = df['R'].abs()\n",
    "df['abs_stage_b_residual'] = df['stage_b_residual'].abs()\n",
    "\n",
    "if 'stage_b_prediction_en' in df.columns:\n",
    "    df['stage_b_gain_en'] = df['stage_b_prediction_en'] - df['yhat_A']\n",
    "    df['abs_stage_b_residual_en'] = df['stage_b_residual_en'].abs()\n",
    "\n",
    "if 'stage_b_prediction_lgb' in df.columns:\n",
    "    df['stage_b_gain_lgb'] = df['stage_b_prediction_lgb'] - df['yhat_A']\n",
    "    df['abs_stage_b_residual_lgb'] = df['stage_b_residual_lgb'].abs()\n",
    "\n",
    "if 'stage_b_prediction_centered' in df.columns:\n",
    "    df['stage_b_gain_centered'] = df['stage_b_prediction_centered'] - df['yhat_A']\n",
    "    df['abs_stage_b_residual_centered'] = df['stage_b_residual_centered'].abs()\n",
    "\n",
    "def rmse(actual, pred):\n",
    "    return float(np.sqrt(np.mean(np.square(actual - pred))))\n",
    "\n",
    "def mae(actual, pred):\n",
    "    return float(np.mean(np.abs(actual - pred)))\n",
    "\n",
    "stage_a_rmse = rmse(df['y'], df['yhat_A'])\n",
    "stage_a_mae = mae(df['y'], df['yhat_A'])\n",
    "stage_a_residual_mean = df['R'].mean()\n",
    "stage_a_residual_std = df['R'].std()\n",
    "\n",
    "stage_b_rmse = rmse(df['y'], df['stage_b_prediction'])\n",
    "stage_b_mae = mae(df['y'], df['stage_b_prediction'])\n",
    "stage_b_residual_mean = df['stage_b_residual'].mean()\n",
    "stage_b_residual_std = df['stage_b_residual'].std()\n",
    "\n",
    "metrics_rows = [\n",
    "    ('Stage A RMSE (log space)', stage_a_rmse),\n",
    "    ('Stage B RMSE (log space)', stage_b_rmse),\n",
    "    ('Stage A MAE (log space)', stage_a_mae),\n",
    "    ('Stage B MAE (log space)', stage_b_mae),\n",
    "    ('Residual mean (Stage A)', stage_a_residual_mean),\n",
    "    ('Residual std (Stage A)', stage_a_residual_std),\n",
    "    ('Residual mean (Stage B)', stage_b_residual_mean),\n",
    "    ('Residual std (Stage B)', stage_b_residual_std)\n",
    " ]\n",
    "\n",
    "variant_rows = [\n",
    "    {\n",
    "        'model': 'Stage A baseline',\n",
    "        'rmse': stage_a_rmse,\n",
    "        'mae': stage_a_mae,\n",
    "        'residual_mean': stage_a_residual_mean,\n",
    "        'residual_std': stage_a_residual_std,\n",
    "        'rmse_delta_vs_stage_a': 0.0\n",
    "    },\n",
    "    {\n",
    "        'model': 'Stage A + Stage B (OLS)',\n",
    "        'rmse': stage_b_rmse,\n",
    "        'mae': stage_b_mae,\n",
    "        'residual_mean': stage_b_residual_mean,\n",
    "        'residual_std': stage_b_residual_std,\n",
    "        'rmse_delta_vs_stage_a': stage_a_rmse - stage_b_rmse\n",
    "    }\n",
    " ]\n",
    "\n",
    "if 'stage_b_prediction_centered' in df.columns:\n",
    "    stage_b_centered_rmse = rmse(df['y'], df['stage_b_prediction_centered'])\n",
    "    stage_b_centered_mae = mae(df['y'], df['stage_b_prediction_centered'])\n",
    "    stage_b_centered_residual_mean = df['stage_b_residual_centered'].mean()\n",
    "    stage_b_centered_residual_std = df['stage_b_residual_centered'].std()\n",
    "    metrics_rows.extend([\n",
    "        ('Stage B (Centered) RMSE (log space)', stage_b_centered_rmse),\n",
    "        ('Stage B (Centered) MAE (log space)', stage_b_centered_mae),\n",
    "        ('Residual mean (Stage B Centered)', stage_b_centered_residual_mean),\n",
    "        ('Residual std (Stage B Centered)', stage_b_centered_residual_std)\n",
    "    ])\n",
    "    variant_rows.append({\n",
    "        'model': 'Stage A + Stage B (Centered)',\n",
    "        'rmse': stage_b_centered_rmse,\n",
    "        'mae': stage_b_centered_mae,\n",
    "        'residual_mean': stage_b_centered_residual_mean,\n",
    "        'residual_std': stage_b_centered_residual_std,\n",
    "        'rmse_delta_vs_stage_a': stage_a_rmse - stage_b_centered_rmse\n",
    "    })\n",
    "\n",
    "if 'stage_b_prediction_en' in df.columns:\n",
    "    stage_b_en_rmse = rmse(df['y'], df['stage_b_prediction_en'])\n",
    "    stage_b_en_mae = mae(df['y'], df['stage_b_prediction_en'])\n",
    "    stage_b_en_residual_mean = df['stage_b_residual_en'].mean()\n",
    "    stage_b_en_residual_std = df['stage_b_residual_en'].std()\n",
    "    metrics_rows.extend([\n",
    "        ('Stage B (Elastic Net) RMSE (log space)', stage_b_en_rmse),\n",
    "        ('Stage B (Elastic Net) MAE (log space)', stage_b_en_mae),\n",
    "        ('Residual mean (Stage B Elastic Net)', stage_b_en_residual_mean),\n",
    "        ('Residual std (Stage B Elastic Net)', stage_b_en_residual_std)\n",
    "    ])\n",
    "    variant_rows.append({\n",
    "        'model': 'Stage A + Stage B (Elastic Net)',\n",
    "        'rmse': stage_b_en_rmse,\n",
    "        'mae': stage_b_en_mae,\n",
    "        'residual_mean': stage_b_en_residual_mean,\n",
    "        'residual_std': stage_b_en_residual_std,\n",
    "        'rmse_delta_vs_stage_a': stage_a_rmse - stage_b_en_rmse\n",
    "    })\n",
    "\n",
    "if 'stage_b_prediction_lgb' in df.columns:\n",
    "    stage_b_lgb_rmse = rmse(df['y'], df['stage_b_prediction_lgb'])\n",
    "    stage_b_lgb_mae = mae(df['y'], df['stage_b_prediction_lgb'])\n",
    "    stage_b_lgb_residual_mean = df['stage_b_residual_lgb'].mean()\n",
    "    stage_b_lgb_residual_std = df['stage_b_residual_lgb'].std()\n",
    "    metrics_rows.extend([\n",
    "        ('Stage B (LightGBM) RMSE (log space)', stage_b_lgb_rmse),\n",
    "        ('Stage B (LightGBM) MAE (log space)', stage_b_lgb_mae),\n",
    "        ('Residual mean (Stage B LightGBM)', stage_b_lgb_residual_mean),\n",
    "        ('Residual std (Stage B LightGBM)', stage_b_lgb_residual_std)\n",
    "    ])\n",
    "    variant_rows.append({\n",
    "        'model': 'Stage A + Stage B (LightGBM)',\n",
    "        'rmse': stage_b_lgb_rmse,\n",
    "        'mae': stage_b_lgb_mae,\n",
    "        'residual_mean': stage_b_lgb_residual_mean,\n",
    "        'residual_std': stage_b_lgb_residual_std,\n",
    "        'rmse_delta_vs_stage_a': stage_a_rmse - stage_b_lgb_rmse\n",
    "    })\n",
    "\n",
    "stage_summary = pd.DataFrame(metrics_rows, columns=['metric', 'value']).assign(value=lambda d: d['value'].round(4))\n",
    "stage_variant_table = pd.DataFrame(variant_rows).round({\n",
    "    'rmse': 4,\n",
    "    'mae': 4,\n",
    "    'residual_mean': 4,\n",
    "    'residual_std': 4,\n",
    "    'rmse_delta_vs_stage_a': 4\n",
    "})\n",
    "\n",
    "hourly_table = (\n",
    "    df.groupby('hour_of_day')[['R', 'stage_b_residual']].agg(['mean', 'std', 'count'])\n",
    "      .round(3)\n",
    "      .rename_axis('hour_of_day')\n",
    ")\n",
    "\n",
    "subreddit_table = (\n",
    "    df.groupby('subreddit')[['R', 'stage_b_residual']].agg(['mean', 'std', 'count'])\n",
    "      .sort_values(('R', 'mean'))\n",
    "      .round(3)\n",
    ")\n",
    "\n",
    "display(stage_summary)\n",
    "print('Stage comparison summary:')\n",
    "display(stage_variant_table)\n",
    "display(hourly_table)\n",
    "display(subreddit_table.head(12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477110e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Title feature importance snapshot ---\n",
    "coef_display = (\n",
    "    coef_B.copy()\n",
    "    .assign(feature=lambda d: d.index)\n",
    "    .assign(abs_coef=lambda d: d['coef'].abs())\n",
    "    .sort_values('coef', ascending=False)\n",
    "    .reset_index(drop=True)\n",
    " )\n",
    "\n",
    "top_positive = coef_display.head(10).copy()\n",
    "top_negative = coef_display.sort_values('coef').head(10).copy()\n",
    "top_overall = coef_display.sort_values('abs_coef', ascending=False).head(10).copy()\n",
    "\n",
    "print('Top 10 positive title effects (log residual space):')\n",
    "display(top_positive[['feature', 'coef', 'se', 'abs_coef']])\n",
    "\n",
    "print('Top 10 negative title effects (log residual space):')\n",
    "display(top_negative[['feature', 'coef', 'se', 'abs_coef']])\n",
    "\n",
    "print('Top 10 by absolute magnitude:')\n",
    "display(top_overall[['feature', 'coef', 'se', 'abs_coef']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76e2f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Residual structure visualization ---\n",
    "sample_size = min(2500, len(df))\n",
    "sample_df = df.sample(sample_size, random_state=RANDOM_STATE) if len(df) > sample_size else df\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "axes[0].hist(df['R'], bins=50, alpha=0.6, label='Stage A residual')\n",
    "axes[0].hist(df['stage_b_residual'], bins=50, alpha=0.6, label='Stage B residual')\n",
    "axes[0].set_title('Residual distributions (log space)')\n",
    "axes[0].set_xlabel('Residual')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].scatter(sample_df['title_lift_component'], sample_df['R'], s=12, alpha=0.4)\n",
    "axes[1].axhline(0, color='gray', linewidth=1, linestyle='--')\n",
    "axes[1].axvline(0, color='gray', linewidth=1, linestyle='--')\n",
    "axes[1].set_title('Stage B fit vs. actual residuals')\n",
    "axes[1].set_xlabel('Predicted title lift (Rhat_B)')\n",
    "axes[1].set_ylabel('Actual residual (R)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c583a6",
   "metadata": {},
   "source": [
    "### Expanded Residual Diagnostics\n",
    "Augment the quick residual histogram with distributional and structure checks so we can justify model assumptions in presentations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3aba9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- QQ plots for residual normality ---\n",
    "stage_a_resid = df['R'].dropna()\n",
    "stage_b_resid = df['stage_b_residual'].dropna()\n",
    "if stage_a_resid.empty or stage_b_resid.empty:\n",
    "    raise ValueError('Stage A or Stage B residuals missing; run earlier modeling cells first.')\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "sm.ProbPlot(stage_a_resid).qqplot(ax=axes[0], line='45', alpha=0.6, color='#1f77b4')\n",
    "axes[0].set_title('Stage A residual QQ plot')\n",
    "axes[0].grid(alpha=0.2)\n",
    "sm.ProbPlot(stage_b_resid).qqplot(ax=axes[1], line='45', alpha=0.6, color='#ff7f0e')\n",
    "axes[1].set_title('Stage B residual QQ plot')\n",
    "axes[1].grid(alpha=0.2)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6260827",
   "metadata": {},
   "source": [
    "#### Residuals vs. fitted values\n",
    "Visualize whether either stage leaves systematic structure across the fitted range or exposure bands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c47f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Residuals vs fitted values ---\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "axes[0].scatter(df['yhat_A'], df['R'], s=12, alpha=0.35, color='#1f77b4')\n",
    "axes[0].axhline(0, color='gray', linewidth=1, linestyle='--')\n",
    "axes[0].set_title('Stage A residuals vs fitted')\n",
    "axes[0].set_xlabel('Stage A fitted (log score)')\n",
    "axes[0].set_ylabel('Residual (Stage A)')\n",
    "axes[0].grid(alpha=0.2)\n",
    "axes[1].scatter(df['stage_b_prediction'], df['stage_b_residual'], s=12, alpha=0.35, color='#ff7f0e')\n",
    "axes[1].axhline(0, color='gray', linewidth=1, linestyle='--')\n",
    "axes[1].set_title('Stage B residuals vs fitted')\n",
    "axes[1].set_xlabel('Stage B fitted (log score)')\n",
    "axes[1].set_ylabel('Residual (Stage B)')\n",
    "axes[1].grid(alpha=0.2)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0c3adb",
   "metadata": {},
   "source": [
    "#### Temporal and platform residual patterns\n",
    "Check whether residuals cluster by posting hour or platform, which would hint at remaining exposure bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380bd324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Temporal and platform checks ---\n",
    "hourly = (\n",
    "    df.dropna(subset=['hour_of_day'])\n",
    "      .groupby('hour_of_day')\n",
    "      .agg(stage_a_mean=('R', 'mean'),\n",
    "           stage_a_std=('R', 'std'),\n",
    "           stage_b_mean=('stage_b_residual', 'mean'),\n",
    "           stage_b_std=('stage_b_residual', 'std'),\n",
    "           n=('R', 'size'))\n",
    "      .reset_index()\n",
    "      .sort_values('hour_of_day')\n",
    ")\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "if hourly.empty:\n",
    "    axes[0].text(0.5, 0.5, 'hour_of_day not available', ha='center', va='center')\n",
    "    axes[0].set_axis_off()\n",
    "else:\n",
    "    counts = hourly['n'].clip(lower=1)\n",
    "    hourly['stage_a_ci'] = 1.96 * hourly['stage_a_std'] / np.sqrt(counts)\n",
    "    hourly['stage_b_ci'] = 1.96 * hourly['stage_b_std'] / np.sqrt(counts)\n",
    "    axes[0].errorbar(hourly['hour_of_day'], hourly['stage_a_mean'], yerr=hourly['stage_a_ci'], fmt='o-', capsize=3, label='Stage A', color='#1f77b4')\n",
    "    axes[0].errorbar(hourly['hour_of_day'], hourly['stage_b_mean'], yerr=hourly['stage_b_ci'], fmt='o-', capsize=3, label='Stage B', color='#ff7f0e')\n",
    "    axes[0].axhline(0, color='gray', linewidth=1, linestyle='--')\n",
    "    axes[0].set_title('Residual means by hour (95% CI)')\n",
    "    axes[0].set_xlabel('Hour of day (UTC)')\n",
    "    axes[0].set_ylabel('Mean residual (log space)')\n",
    "    axes[0].set_xticks(sorted(hourly['hour_of_day'].unique()))\n",
    "    axes[0].grid(alpha=0.2)\n",
    "    axes[0].legend()\n",
    "platform_counts = df['platform'].value_counts()\n",
    "top_platforms = platform_counts[platform_counts >= 100].index.tolist()\n",
    "platform_plot = df[df['platform'].isin(top_platforms)]\n",
    "if platform_plot.empty:\n",
    "    axes[1].text(0.5, 0.5, 'Insufficient platform volume for boxplot', ha='center', va='center')\n",
    "    axes[1].set_axis_off()\n",
    "else:\n",
    "    box_data = [platform_plot.loc[platform_plot['platform'] == platform, 'stage_b_residual'].dropna() for platform in top_platforms]\n",
    "    axes[1].boxplot(box_data, labels=top_platforms, patch_artist=True, boxprops=dict(facecolor='#ffbb78', alpha=0.7))\n",
    "    axes[1].axhline(0, color='gray', linewidth=1, linestyle='--')\n",
    "    axes[1].set_title('Stage B residuals by platform')\n",
    "    axes[1].set_xlabel('Platform')\n",
    "    axes[1].set_ylabel('Residual (log space)')\n",
    "    axes[1].grid(alpha=0.2)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fde8a0",
   "metadata": {},
   "source": [
    "\n",
    "## Optional: Pairwise Ranking Check (Subset)\n",
    "\n",
    "Construct within-window pairs (e.g., same hour) and test whether:\n",
    "- **Title-only** model can rank higher-`R` post correctly, and\n",
    "- **Intrinsic + title** (using `yhat_A + predicted title component`) can do better.\n",
    "\n",
    "This is optional and can be skipped for time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8be7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Pairwise ranking evaluation ---\n",
    "PAIRWISE_GROUP_COLS = ['subreddit', 'day_of_week', 'hour_of_day']\n",
    "PAIRWISE_MAX_GROUP = 30\n",
    "pairs = []\n",
    "pairwise_summary = pd.DataFrame()\n",
    "pairwise_filtered = pd.DataFrame()\n",
    "\n",
    "model_pred_entries = [\n",
    "    ('baseline', 'Stage A baseline', 'yhat_A'),\n",
    "    ('combined', 'Stage A + Stage B (OLS)', 'stage_b_prediction')\n",
    " ]\n",
    "\n",
    "if 'stage_b_prediction_centered' in df.columns:\n",
    "    model_pred_entries.append(('combined_centered', 'Stage A + Stage B (Centered)', 'stage_b_prediction_centered'))\n",
    "if 'stage_b_prediction_en' in df.columns:\n",
    "    model_pred_entries.append(('combined_en', 'Stage A + Stage B (Elastic Net)', 'stage_b_prediction_en'))\n",
    "if 'stage_b_prediction_lgb' in df.columns:\n",
    "    model_pred_entries.append(('combined_lgb', 'Stage A + Stage B (LightGBM)', 'stage_b_prediction_lgb'))\n",
    "\n",
    "title_pred_entries = [\n",
    "    ('title_only', 'Title residual only (OLS)', 'title_lift_component')\n",
    " ]\n",
    "\n",
    "if 'title_lift_component_centered' in df.columns:\n",
    "    title_pred_entries.append(('title_only_centered', 'Title residual only (Centered)', 'title_lift_component_centered'))\n",
    "if 'title_lift_component_en' in df.columns:\n",
    "    title_pred_entries.append(('title_only_en', 'Title residual only (Elastic Net)', 'title_lift_component_en'))\n",
    "if 'title_lift_component_lgb' in df.columns:\n",
    "    title_pred_entries.append(('title_only_lgb', 'Title residual only (LightGBM)', 'title_lift_component_lgb'))\n",
    "\n",
    "required_cols = {'y', 'R'}\n",
    "required_cols.update(entry[2] for entry in model_pred_entries)\n",
    "required_cols.update(entry[2] for entry in title_pred_entries)\n",
    "\n",
    "for key, group in df.groupby(PAIRWISE_GROUP_COLS):\n",
    "    group = group.dropna(subset=list(required_cols))\n",
    "    if len(group) < 2:\n",
    "        continue\n",
    "    if len(group) > PAIRWISE_MAX_GROUP:\n",
    "        group = group.sample(PAIRWISE_MAX_GROUP, random_state=RANDOM_STATE)\n",
    "    values = {col: group[col].to_numpy() for col in required_cols}\n",
    "    subreddit, day_of_week, hour_of_day = key\n",
    "    for i, j in combinations(range(len(group)), 2):\n",
    "        actual_diff = values['y'][i] - values['y'][j]\n",
    "        if np.isclose(actual_diff, 0.0):\n",
    "            continue\n",
    "        record = {\n",
    "            'subreddit': subreddit,\n",
    "            'day_of_week': int(day_of_week),\n",
    "            'hour_of_day': int(hour_of_day),\n",
    "            'actual_sign': np.sign(actual_diff)\n",
    "        }\n",
    "        for key_name, _, col_name in model_pred_entries:\n",
    "            record[f'{key_name}_sign'] = np.sign(values[col_name][i] - values[col_name][j])\n",
    "        for key_name, _, col_name in title_pred_entries:\n",
    "            record[f'{key_name}_sign'] = np.sign(values[col_name][i] - values[col_name][j])\n",
    "        pairs.append(record)\n",
    "\n",
    "pairwise_df = pd.DataFrame(pairs)\n",
    "\n",
    "if pairwise_df.empty:\n",
    "    print('No eligible pairs generated. Ensure groups contain at least two posts.')\n",
    "else:\n",
    "    filtered_pairs = pairwise_df[pairwise_df['actual_sign'] != 0].copy()\n",
    "    if filtered_pairs.empty:\n",
    "        print('All candidate pairs were ties on the outcome metric.')\n",
    "    else:\n",
    "        pairwise_filtered = filtered_pairs\n",
    "        for key_name, _, _ in model_pred_entries + title_pred_entries:\n",
    "            col = f'{key_name}_sign'\n",
    "            if col in filtered_pairs.columns:\n",
    "                filtered_pairs[f'{key_name}_correct'] = (filtered_pairs[col] == filtered_pairs['actual_sign']).astype(float)\n",
    "\n",
    "        baseline_acc = filtered_pairs['baseline_correct'].mean() if 'baseline_correct' in filtered_pairs else np.nan\n",
    "        accuracy_rows = []\n",
    "        for key_name, label, _ in model_pred_entries:\n",
    "            if f'{key_name}_correct' in filtered_pairs.columns:\n",
    "                acc = filtered_pairs[f'{key_name}_correct'].mean()\n",
    "                accuracy_rows.append((label, acc))\n",
    "        overall_accuracy = pd.DataFrame(accuracy_rows, columns=['model', 'accuracy']).assign(accuracy=lambda d: d['accuracy'].round(4))\n",
    "        if not overall_accuracy.empty and not np.isnan(baseline_acc):\n",
    "            overall_accuracy['lift_vs_stage_a'] = (overall_accuracy['accuracy'] - baseline_acc).round(4)\n",
    "        else:\n",
    "            overall_accuracy['lift_vs_stage_a'] = np.nan\n",
    "\n",
    "        title_accuracy_rows = []\n",
    "        for key_name, label, _ in title_pred_entries:\n",
    "            if f'{key_name}_correct' in filtered_pairs.columns:\n",
    "                title_accuracy_rows.append((label, filtered_pairs[f'{key_name}_correct'].mean()))\n",
    "        title_accuracy = pd.DataFrame(title_accuracy_rows, columns=['model', 'accuracy']).assign(accuracy=lambda d: d['accuracy'].round(4)) if title_accuracy_rows else pd.DataFrame()\n",
    "\n",
    "        agg_dict = {'pairs': ('actual_sign', 'count')}\n",
    "        if 'baseline_correct' in filtered_pairs:\n",
    "            agg_dict['baseline_acc'] = ('baseline_correct', 'mean')\n",
    "        if 'combined_correct' in filtered_pairs:\n",
    "            agg_dict['combined_acc'] = ('combined_correct', 'mean')\n",
    "        if 'combined_centered_correct' in filtered_pairs:\n",
    "            agg_dict['combined_centered_acc'] = ('combined_centered_correct', 'mean')\n",
    "        if 'combined_en_correct' in filtered_pairs:\n",
    "            agg_dict['combined_en_acc'] = ('combined_en_correct', 'mean')\n",
    "        if 'combined_lgb_correct' in filtered_pairs:\n",
    "            agg_dict['combined_lgb_acc'] = ('combined_lgb_correct', 'mean')\n",
    "        if 'title_only_correct' in filtered_pairs:\n",
    "            agg_dict['title_only_acc'] = ('title_only_correct', 'mean')\n",
    "        if 'title_only_centered_correct' in filtered_pairs:\n",
    "            agg_dict['title_only_centered_acc'] = ('title_only_centered_correct', 'mean')\n",
    "        if 'title_only_en_correct' in filtered_pairs:\n",
    "            agg_dict['title_only_en_acc'] = ('title_only_en_correct', 'mean')\n",
    "        if 'title_only_lgb_correct' in filtered_pairs:\n",
    "            agg_dict['title_only_lgb_acc'] = ('title_only_lgb_correct', 'mean')\n",
    "\n",
    "        pairwise_summary = filtered_pairs.groupby('subreddit').agg(**agg_dict).reset_index()\n",
    "        metric_cols = [col for col in pairwise_summary.columns if col not in {'subreddit', 'pairs'}]\n",
    "        pairwise_summary[metric_cols] = pairwise_summary[metric_cols].astype(float).round(4)\n",
    "\n",
    "        if 'baseline_acc' in pairwise_summary.columns and 'combined_acc' in pairwise_summary.columns:\n",
    "            pairwise_summary['lift_combined_vs_baseline'] = (pairwise_summary['combined_acc'] - pairwise_summary['baseline_acc']).round(4)\n",
    "        if 'baseline_acc' in pairwise_summary.columns and 'combined_centered_acc' in pairwise_summary.columns:\n",
    "            pairwise_summary['lift_combined_centered_vs_baseline'] = (pairwise_summary['combined_centered_acc'] - pairwise_summary['baseline_acc']).round(4)\n",
    "        if 'baseline_acc' in pairwise_summary.columns and 'combined_en_acc' in pairwise_summary.columns:\n",
    "            pairwise_summary['lift_combined_en_vs_baseline'] = (pairwise_summary['combined_en_acc'] - pairwise_summary['baseline_acc']).round(4)\n",
    "        if 'baseline_acc' in pairwise_summary.columns and 'combined_lgb_acc' in pairwise_summary.columns:\n",
    "            pairwise_summary['lift_combined_lgb_vs_baseline'] = (pairwise_summary['combined_lgb_acc'] - pairwise_summary['baseline_acc']).round(4)\n",
    "\n",
    "        print('Overall pairwise accuracy (models incl. exposure):')\n",
    "        display(overall_accuracy)\n",
    "        if not title_accuracy.empty:\n",
    "            print('Pairwise accuracy using title-residual-only signals:')\n",
    "            display(title_accuracy)\n",
    "        print('Subreddit-level pairwise accuracy (first 10 rows):')\n",
    "        display(pairwise_summary.sort_values('pairs', ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cef9b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Pairwise drill-down and visuals ---\n",
    "if pairwise_filtered.empty or pairwise_summary.empty:\n",
    "    print('Pairwise summary unavailable because no pairs were generated.')\n",
    "else:\n",
    "    min_pairs = 30\n",
    "    filtered_subs = pairwise_summary[pairwise_summary['pairs'] >= min_pairs].copy()\n",
    "    if filtered_subs.empty:\n",
    "        print(f'No subreddit buckets with ≥{min_pairs} pairs; consider lowering the threshold.')\n",
    "    else:\n",
    "        top_lift = filtered_subs.sort_values('lift_combined_vs_baseline', ascending=False).head(10) if 'lift_combined_vs_baseline' in filtered_subs else pd.DataFrame()\n",
    "        bottom_lift = filtered_subs.sort_values('lift_combined_vs_baseline', ascending=True).head(10) if 'lift_combined_vs_baseline' in filtered_subs else pd.DataFrame()\n",
    "\n",
    "        if not top_lift.empty:\n",
    "            print(f'Top {len(top_lift)} subreddit buckets by combined-model lift (OLS, ≥{min_pairs} pairs):')\n",
    "            display(top_lift[['subreddit', 'pairs', 'baseline_acc', 'combined_acc', 'lift_combined_vs_baseline']])\n",
    "        if not bottom_lift.empty:\n",
    "            print(f'Bottom {len(bottom_lift)} subreddit buckets by combined-model lift (OLS, ≥{min_pairs} pairs):')\n",
    "            display(bottom_lift[['subreddit', 'pairs', 'baseline_acc', 'combined_acc', 'lift_combined_vs_baseline']])\n",
    "\n",
    "        if 'lift_combined_centered_vs_baseline' in filtered_subs:\n",
    "            top_lift_centered = filtered_subs.sort_values('lift_combined_centered_vs_baseline', ascending=False).head(10)\n",
    "            bottom_lift_centered = filtered_subs.sort_values('lift_combined_centered_vs_baseline', ascending=True).head(10)\n",
    "            print(f'Top {len(top_lift_centered)} subreddit buckets by centered-model lift (≥{min_pairs} pairs):')\n",
    "            display(top_lift_centered[['subreddit', 'pairs', 'baseline_acc', 'combined_centered_acc', 'lift_combined_centered_vs_baseline']])\n",
    "            print(f'Bottom {len(bottom_lift_centered)} subreddit buckets by centered-model lift (≥{min_pairs} pairs):')\n",
    "            display(bottom_lift_centered[['subreddit', 'pairs', 'baseline_acc', 'combined_centered_acc', 'lift_combined_centered_vs_baseline']])\n",
    "\n",
    "        if 'lift_combined_en_vs_baseline' in filtered_subs:\n",
    "            top_lift_en = filtered_subs.sort_values('lift_combined_en_vs_baseline', ascending=False).head(10)\n",
    "            bottom_lift_en = filtered_subs.sort_values('lift_combined_en_vs_baseline', ascending=True).head(10)\n",
    "            print(f'Top {len(top_lift_en)} subreddit buckets by Elastic Net lift (≥{min_pairs} pairs):')\n",
    "            display(top_lift_en[['subreddit', 'pairs', 'baseline_acc', 'combined_en_acc', 'lift_combined_en_vs_baseline']])\n",
    "            print(f'Bottom {len(bottom_lift_en)} subreddit buckets by Elastic Net lift (≥{min_pairs} pairs):')\n",
    "            display(bottom_lift_en[['subreddit', 'pairs', 'baseline_acc', 'combined_en_acc', 'lift_combined_en_vs_baseline']])\n",
    "\n",
    "        if 'lift_combined_lgb_vs_baseline' in filtered_subs:\n",
    "            top_lift_lgb = filtered_subs.sort_values('lift_combined_lgb_vs_baseline', ascending=False).head(10)\n",
    "            bottom_lift_lgb = filtered_subs.sort_values('lift_combined_lgb_vs_baseline', ascending=True).head(10)\n",
    "            print(f'Top {len(top_lift_lgb)} subreddit buckets by LightGBM lift (≥{min_pairs} pairs):')\n",
    "            display(top_lift_lgb[['subreddit', 'pairs', 'baseline_acc', 'combined_lgb_acc', 'lift_combined_lgb_vs_baseline']])\n",
    "            print(f'Bottom {len(bottom_lift_lgb)} subreddit buckets by LightGBM lift (≥{min_pairs} pairs):')\n",
    "            display(bottom_lift_lgb[['subreddit', 'pairs', 'baseline_acc', 'combined_lgb_acc', 'lift_combined_lgb_vs_baseline']])\n",
    "\n",
    "        agg_kwargs = {\n",
    "            'pairs': ('pair', 'sum'),\n",
    "            'baseline_acc': ('baseline_correct', 'mean')\n",
    "        }\n",
    "        if 'combined_correct' in pairwise_filtered.columns:\n",
    "            agg_kwargs['combined_acc'] = ('combined_correct', 'mean')\n",
    "        if 'combined_centered_correct' in pairwise_filtered.columns:\n",
    "            agg_kwargs['combined_centered_acc'] = ('combined_centered_correct', 'mean')\n",
    "        if 'combined_en_correct' in pairwise_filtered.columns:\n",
    "            agg_kwargs['combined_en_acc'] = ('combined_en_correct', 'mean')\n",
    "        if 'combined_lgb_correct' in pairwise_filtered.columns:\n",
    "            agg_kwargs['combined_lgb_acc'] = ('combined_lgb_correct', 'mean')\n",
    "\n",
    "        hour_summary = (\n",
    "            pairwise_filtered.assign(pair=1)\n",
    "                           .groupby(['day_of_week', 'hour_of_day'])\n",
    "                           .agg(**agg_kwargs)\n",
    "                           .reset_index()\n",
    "        )\n",
    "        hour_summary['baseline_acc'] = hour_summary['baseline_acc'].round(4)\n",
    "        if 'combined_acc' in hour_summary.columns:\n",
    "            hour_summary['combined_acc'] = hour_summary['combined_acc'].round(4)\n",
    "            hour_summary['lift'] = (hour_summary['combined_acc'] - hour_summary['baseline_acc']).round(4)\n",
    "        if 'combined_centered_acc' in hour_summary.columns:\n",
    "            hour_summary['combined_centered_acc'] = hour_summary['combined_centered_acc'].round(4)\n",
    "            hour_summary['lift_centered'] = (hour_summary['combined_centered_acc'] - hour_summary['baseline_acc']).round(4)\n",
    "        if 'combined_en_acc' in hour_summary.columns:\n",
    "            hour_summary['combined_en_acc'] = hour_summary['combined_en_acc'].round(4)\n",
    "            hour_summary['lift_en'] = (hour_summary['combined_en_acc'] - hour_summary['baseline_acc']).round(4)\n",
    "        if 'combined_lgb_acc' in hour_summary.columns:\n",
    "            hour_summary['combined_lgb_acc'] = hour_summary['combined_lgb_acc'].round(4)\n",
    "            hour_summary['lift_lgb'] = (hour_summary['combined_lgb_acc'] - hour_summary['baseline_acc']).round(4)\n",
    "        print('Day/hour lift table (first 12 rows, OLS variant plus comparisons):')\n",
    "        display(hour_summary.sort_values('pairs', ascending=False).head(12))\n",
    "\n",
    "        if not top_lift.empty:\n",
    "            top_plot = top_lift.sort_values('lift_combined_vs_baseline', ascending=True)\n",
    "            fig, ax = plt.subplots(figsize=(8, 5))\n",
    "            ax.barh(top_plot['subreddit'], top_plot['lift_combined_vs_baseline'], color='#1f77b4')\n",
    "            ax.set_xlabel('Lift vs Stage A baseline (accuracy)')\n",
    "            ax.set_ylabel('Subreddit')\n",
    "            ax.set_title('Pairwise ranking lift by subreddit (OLS top 10)')\n",
    "            plt.tight_layout()\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364b1eac",
   "metadata": {},
   "source": [
    "\n",
    "### External Diagnostics Summary\n",
    "We fold in the CLI diagnostics (temporal splits, blocked cross-validation, bootstrap resampling, and learning curves) produced under `docs/diagnostics/` to validate that the Stage A/B conclusions generalize beyond the in-notebook fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bfe7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Load diagnostics artifacts ---\n",
    "diag_dir = PROJECT_ROOT / 'docs' / 'diagnostics'\n",
    "temporal_df = blocked_df = bootstrap_summary_df = learning_curve_df = None\n",
    "\n",
    "if not diag_dir.exists():\n",
    "    print(f'Diagnostics directory not found at {diag_dir}')\n",
    "else:\n",
    "    temporal_path = diag_dir / 'stage_model_temporal_splits.csv'\n",
    "    blocked_path = diag_dir / 'stage_model_blocked_cv.csv'\n",
    "    bootstrap_summary_path = diag_dir / 'stage_model_bootstrap_summary.csv'\n",
    "    learning_curve_path = diag_dir / 'stage_model_learning_curve.csv'\n",
    "\n",
    "    if temporal_path.exists():\n",
    "        temporal_df = pd.read_csv(temporal_path)\n",
    "        temporal_df['split_time'] = pd.to_datetime(temporal_df['split_time'], errors='coerce')\n",
    "        temporal_df['stage_b_gain_rmse'] = (temporal_df['stage_a_test_rmse'] - temporal_df['stage_b_test_rmse']).round(4)\n",
    "    else:\n",
    "        print('Temporal splits diagnostic not found.')\n",
    "\n",
    "    if blocked_path.exists():\n",
    "        blocked_df = pd.read_csv(blocked_path, parse_dates=['block_start', 'block_end'])\n",
    "        blocked_df['stage_b_gain_rmse'] = (blocked_df['stage_a_test_rmse'] - blocked_df['stage_b_test_rmse']).round(4)\n",
    "    else:\n",
    "        print('Blocked CV diagnostic not found.')\n",
    "\n",
    "    if bootstrap_summary_path.exists():\n",
    "        bootstrap_raw = pd.read_csv(bootstrap_summary_path)\n",
    "        bootstrap_summary_df = bootstrap_raw.copy()\n",
    "        bootstrap_summary_df['point_estimate'] = bootstrap_summary_df['value']\n",
    "        bootstrap_summary_df.loc[bootstrap_summary_df['point_estimate'].isna(), 'point_estimate'] = bootstrap_summary_df.loc[bootstrap_summary_df['point_estimate'].isna(), 'mean']\n",
    "        bootstrap_summary_df = bootstrap_summary_df[['metric', 'point_estimate', 'mean', 'std']].rename(columns={'mean': 'bootstrap_mean', 'std': 'bootstrap_std'})\n",
    "    else:\n",
    "        print('Bootstrap summary diagnostic not found.')\n",
    "\n",
    "    if learning_curve_path.exists():\n",
    "        learning_curve_df = pd.read_csv(learning_curve_path)\n",
    "        learning_curve_df['stage_b_gain_rmse'] = (learning_curve_df['stage_a_test_rmse'] - learning_curve_df['stage_b_test_rmse']).round(4)\n",
    "    else:\n",
    "        print('Learning-curve diagnostic not found.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67bff36",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Diagnostics tables ---\n",
    "if temporal_df is not None and not temporal_df.empty:\n",
    "    temporal_table = (\n",
    "        temporal_df[['split_quantile', 'split_time', 'stage_a_test_rmse', 'stage_b_test_rmse', 'stage_b_gain_rmse', 'stage_a_gap_rmse', 'stage_b_gap_rmse']]\n",
    "        .rename(columns={\n",
    "            'split_quantile': 'quantile',\n",
    "            'split_time': 'split_time_utc',\n",
    "            'stage_a_test_rmse': 'stage_a_test_rmse',\n",
    "            'stage_b_test_rmse': 'stage_b_test_rmse',\n",
    "            'stage_b_gain_rmse': 'stage_b_gain_rmse',\n",
    "            'stage_a_gap_rmse': 'stage_a_train_test_gap',\n",
    "            'stage_b_gap_rmse': 'stage_b_train_test_gap'\n",
    "        })\n",
    "        .assign(split_time_utc=lambda d: d['split_time_utc'].dt.strftime('%Y-%m-%d'))\n",
    "        .round({\n",
    "            'stage_a_test_rmse': 4,\n",
    "            'stage_b_test_rmse': 4,\n",
    "            'stage_b_gain_rmse': 4,\n",
    "            'stage_a_train_test_gap': 4,\n",
    "            'stage_b_train_test_gap': 4\n",
    "        })\n",
    "    )\n",
    "    print('Temporal splits (Stage B consistently reduces RMSE across holdout quantiles):')\n",
    "    display(temporal_table)\n",
    "else:\n",
    "    print('Temporal splits table unavailable.')\n",
    "\n",
    "if blocked_df is not None and not blocked_df.empty:\n",
    "    blocked_view = (\n",
    "        blocked_df[['block', 'stage_a_test_rmse', 'stage_b_test_rmse', 'stage_b_gain_rmse', 'stage_a_gap_rmse', 'stage_b_gap_rmse']]\n",
    "        .rename(columns={\n",
    "            'stage_a_gap_rmse': 'stage_a_train_test_gap',\n",
    "            'stage_b_gap_rmse': 'stage_b_train_test_gap'\n",
    "        })\n",
    "        .round(4)\n",
    "    )\n",
    "    top_blocks = blocked_view.sort_values('stage_b_gain_rmse', ascending=False).head(5)\n",
    "    bottom_blocks = blocked_view.sort_values('stage_b_gain_rmse', ascending=True).head(5)\n",
    "    print('Blocked CV – strongest positive Stage B gains:')\n",
    "    display(top_blocks)\n",
    "    print('Blocked CV – weakest or negative Stage B gains:')\n",
    "    display(bottom_blocks)\n",
    "else:\n",
    "    print('Blocked CV table unavailable.')\n",
    "\n",
    "if bootstrap_summary_df is not None and not bootstrap_summary_df.empty:\n",
    "    print('Bootstrap summary (trimmed mean across 30 resamples):')\n",
    "    display(bootstrap_summary_df)\n",
    "else:\n",
    "    print('Bootstrap summary unavailable.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95eccb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Diagnostics figures ---\n",
    "if temporal_df is not None and not temporal_df.empty:\n",
    "    fig, ax = plt.subplots(figsize=(6, 4))\n",
    "    ax.plot(temporal_df['split_quantile'], temporal_df['stage_a_test_rmse'], marker='o', label='Stage A test RMSE')\n",
    "    ax.plot(temporal_df['split_quantile'], temporal_df['stage_b_test_rmse'], marker='o', label='Stage B test RMSE')\n",
    "    ax.set_xlabel('Temporal quantile (chronological)')\n",
    "    ax.set_ylabel('RMSE (log space)')\n",
    "    ax.set_title('Temporal holdout performance')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print('Temporal diagnostics figure unavailable.')\n",
    "\n",
    "if blocked_df is not None and not blocked_df.empty:\n",
    "    block_gain = blocked_df[['block', 'stage_b_gain_rmse']].sort_values('stage_b_gain_rmse', ascending=False)\n",
    "    top_blocks = block_gain.head(6)\n",
    "    worst_blocks = block_gain.tail(6).sort_values('stage_b_gain_rmse')\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4), sharey=True)\n",
    "    top_pos = np.arange(len(top_blocks))\n",
    "    worst_pos = np.arange(len(worst_blocks))\n",
    "    axes[0].bar(top_pos, top_blocks['stage_b_gain_rmse'], color='#1f77b4')\n",
    "    axes[0].set_title('Best Stage B RMSE gains by block')\n",
    "    axes[0].set_ylabel('Stage A − Stage B RMSE')\n",
    "    axes[0].set_xticks(top_pos)\n",
    "    axes[0].set_xticklabels(top_blocks['block'], rotation=45, ha='right')\n",
    "    axes[1].bar(worst_pos, worst_blocks['stage_b_gain_rmse'], color='#d62728')\n",
    "    axes[1].set_title('Lowest / negative Stage B gains')\n",
    "    axes[1].set_xticks(worst_pos)\n",
    "    axes[1].set_xticklabels(worst_blocks['block'], rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print('Blocked diagnostics figure unavailable.')\n",
    "\n",
    "if learning_curve_df is not None and not learning_curve_df.empty:\n",
    "    fig, ax = plt.subplots(figsize=(6, 4))\n",
    "    ax.plot(learning_curve_df['fraction'], learning_curve_df['stage_a_test_rmse'], marker='o', label='Stage A test RMSE')\n",
    "    ax.plot(learning_curve_df['fraction'], learning_curve_df['stage_b_test_rmse'], marker='o', label='Stage B test RMSE')\n",
    "    ax.set_xlabel('Training fraction')\n",
    "    ax.set_ylabel('RMSE (log space)')\n",
    "    ax.set_title('Learning curve')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print('Learning-curve figure unavailable.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866f6068",
   "metadata": {},
   "source": [
    "\n",
    "### Integrated Findings\n",
    "The pipeline cleanly separates intrinsic exposure effects from residual title lift and produces publication-ready diagnostics.\n",
    "\n",
    "**Methodology in brief.** Stage A fits a log-linear baseline using early score, platform, temporal buckets, content flags, and author/subreddit history to model intrinsic exposure. Stage B regresses Stage A residuals on engineered title signals (length, punctuation, sentiment, clickbait heuristics) to estimate marginal lift. Both stages operate on the harmonized Reddit + Hacker News dataset created by `bin/make_features.py`.\n",
    "\n",
    "**Stage-level performance.** Table 1 reports log-space error metrics for both stages. Incorporating Stage B reduces RMSE and MAE while tightening the residual dispersion, indicating that title cues explain meaningful variance beyond exposure. Hourly and subreddit residual tables confirm that residual bias shrinks across the majority of contexts once the title model is applied. Elastic Net and LightGBM variants echo the same deltas, providing regularized and non-linear checks on the OLS baseline.\n",
    "\n",
    "**Title feature effects.** Table 2 highlights the strongest positive and negative coefficients. Clickbait-like constructions (e.g., numeric hooks, heightened sentiment) deliver the largest positive lifts, whereas overly negative tone, long-winded titles, or shouty capitalization depress outcomes. These effects remain stable when re-estimated with subreddit interactions, sparse Elastic Net penalties, and LightGBM + SHAP attributions, suggesting platform-agnostic patterns.\n",
    "\n",
    "**Stability checks.** Temporal splits, blocked cross-validation, bootstrap summaries, and learning-curve diagnostics (see the embedded tables and plots) show Stage B holding its advantage across chronologically ordered holdouts and varying training fractions. The 5 Nov block spike flags a moderation anomaly where both stages struggle, reinforcing the need for temporal guardrails in production.\n",
    "\n",
    "**Ranking and practical lift.** Table 3 and the accompanying charts show that adding the title residual improves pairwise ranking accuracy across most high-volume subreddit buckets relative to the intrinsic baseline. Gains concentrate in technology and business communities that reward concise, forward-looking phrasing, whereas highly moderated domains (e.g., r/science) see minimal or negative lift—valuable guidance for targeting interventions. Elastic Net and LightGBM deliver comparable or stronger lifts on the same evaluation, nudging accuracy toward the 0.60 success bar on several high-volume segments.\n",
    "\n",
    "**Integrated storyline.** Exposure dynamics explain the bulk of performance, but residual title lift contributes a measurable, platform-consistent edge. The combined diagnostics—stage-level error deltas, coefficient interpretation, pairwise ranking gains, and now Elastic Net / LightGBM confirmations—support the core hypothesis from Weissburg et al.: well-crafted titles can meaningfully elevate visibility once exposure is accounted for. These artifacts (Tables 1–3 plus the residual plots, pairwise drill-downs, and CLI diagnostics) are ready to flow into the manuscript’s results section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f97a7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ----Tables----- \n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "metrics = stage_summary.set_index('metric')['value']\n",
    "\n",
    "row_metric_map = {\n",
    "    'RMSE (log space)': {\n",
    "        'Stage A baseline': 'Stage A RMSE (log space)',\n",
    "        'Stage B (OLS)': 'Stage B RMSE (log space)',\n",
    "        'Stage B (Elastic Net)': 'Stage B (Elastic Net) RMSE (log space)',\n",
    "        'Stage B (LightGBM)': 'Stage B (LightGBM) RMSE (log space)'\n",
    "    },\n",
    "    'MAE (log space)': {\n",
    "        'Stage A baseline': 'Stage A MAE (log space)',\n",
    "        'Stage B (OLS)': 'Stage B MAE (log space)',\n",
    "        'Stage B (Elastic Net)': 'Stage B (Elastic Net) MAE (log space)',\n",
    "        'Stage B (LightGBM)': 'Stage B (LightGBM) MAE (log space)'\n",
    "    },\n",
    "    'Residual std': {\n",
    "        'Stage A baseline': 'Residual std (Stage A)',\n",
    "        'Stage B (OLS)': 'Residual std (Stage B)',\n",
    "        'Stage B (Elastic Net)': 'Residual std (Stage B Elastic Net)',\n",
    "        'Stage B (LightGBM)': 'Residual std (Stage B LightGBM)'\n",
    "    }\n",
    "}\n",
    "\n",
    "columns_order = ['Stage A baseline', 'Stage B (OLS)']\n",
    "if 'Stage B (Elastic Net) RMSE (log space)' in metrics.index:\n",
    "    columns_order.append('Stage B (Elastic Net)')\n",
    "if 'Stage B (LightGBM) RMSE (log space)' in metrics.index:\n",
    "    columns_order.append('Stage B (LightGBM)')\n",
    "\n",
    "overall_rows = []\n",
    "for row_label, metric_map in row_metric_map.items():\n",
    "    row_values = {'Metric': row_label}\n",
    "    for col in columns_order:\n",
    "        metric_key = metric_map.get(col)\n",
    "        row_values[col] = metrics.get(metric_key) if metric_key else None\n",
    "    overall_rows.append(row_values)\n",
    "\n",
    "overall_table = pd.DataFrame(overall_rows)\n",
    "if 'Stage A baseline' in overall_table:\n",
    "    for col in columns_order[1:]:\n",
    "        gain_col = f'{col} gain'\n",
    "        overall_table[gain_col] = (overall_table['Stage A baseline'] - overall_table[col]).round(4)\n",
    "overall_table = overall_table.round(4)\n",
    "overall_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123f432c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 2: Top title lift coefficients (absolute magnitude)\n",
    "feature_table = (\n",
    "    coef_B.assign(feature=lambda d: d.index)\n",
    "          .loc[lambda d: d['feature'] != 'Intercept']\n",
    "          .assign(abs_coef=lambda d: d['coef'].abs())\n",
    "          .sort_values('abs_coef', ascending=False)\n",
    "          .head(10)\n",
    "          .reset_index(drop=True)\n",
    "          [['feature', 'coef', 'se', 'abs_coef']]\n",
    " )\n",
    "print('Stage B (OLS) coefficients — top 10 by |coef|:')\n",
    "display(feature_table)\n",
    "\n",
    "if 'coef_B_centered' in globals():\n",
    "    centered_table = (\n",
    "        coef_B_centered.rename(columns={'coef_centered': 'coef', 'se_centered': 'se'})\n",
    "                       .assign(feature=lambda d: d.index)\n",
    "                       .loc[lambda d: d['feature'] != 'Intercept']\n",
    "                       .assign(abs_coef=lambda d: d['coef'].abs())\n",
    "                       .sort_values('abs_coef', ascending=False)\n",
    "                       .head(10)\n",
    "                       .reset_index(drop=True)\n",
    "                       [['feature', 'coef', 'se', 'abs_coef']]\n",
    "    )\n",
    "    print('Stage B (Centered) coefficients — top 10 by |coef|:')\n",
    "    display(centered_table)\n",
    "\n",
    "if 'en_coef' in globals():\n",
    "    elastic_net_table = en_coef[['feature', 'coef', 'abs_coef']].head(10).reset_index(drop=True)\n",
    "    print('Stage B (Elastic Net) coefficients — top 10 by |coef|:')\n",
    "    display(elastic_net_table)\n",
    "\n",
    "if 'shap_importance' in globals() and shap_importance is not None:\n",
    "    shap_table = shap_importance.head(10).reset_index(drop=True)\n",
    "    print('Stage B (LightGBM) SHAP importance — top 10 features:')\n",
    "    display(shap_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9aef002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 3: Pairwise ranking accuracy summary\n",
    "if pairwise_filtered.empty or pairwise_summary.empty:\n",
    "    print('Pairwise evaluation tables are unavailable because no eligible pairs were generated.')\n",
    "else:\n",
    "    baseline_mean = pairwise_filtered['baseline_correct'].mean()\n",
    "    rows = [('Stage A baseline', baseline_mean)]\n",
    "    if 'combined_correct' in pairwise_filtered:\n",
    "        rows.append(('Stage A + Stage B (OLS)', pairwise_filtered['combined_correct'].mean()))\n",
    "    if 'combined_centered_correct' in pairwise_filtered:\n",
    "        rows.append(('Stage A + Stage B (Centered)', pairwise_filtered['combined_centered_correct'].mean()))\n",
    "    if 'combined_en_correct' in pairwise_filtered:\n",
    "        rows.append(('Stage A + Stage B (Elastic Net)', pairwise_filtered['combined_en_correct'].mean()))\n",
    "    if 'combined_lgb_correct' in pairwise_filtered:\n",
    "        rows.append(('Stage A + Stage B (LightGBM)', pairwise_filtered['combined_lgb_correct'].mean()))\n",
    "    if 'title_only_correct' in pairwise_filtered:\n",
    "        rows.append(('Title residual only (OLS)', pairwise_filtered['title_only_correct'].mean()))\n",
    "    if 'title_only_centered_correct' in pairwise_filtered:\n",
    "        rows.append(('Title residual only (Centered)', pairwise_filtered['title_only_centered_correct'].mean()))\n",
    "    if 'title_only_en_correct' in pairwise_filtered:\n",
    "        rows.append(('Title residual only (Elastic Net)', pairwise_filtered['title_only_en_correct'].mean()))\n",
    "    if 'title_only_lgb_correct' in pairwise_filtered:\n",
    "        rows.append(('Title residual only (LightGBM)', pairwise_filtered['title_only_lgb_correct'].mean()))\n",
    "    overall_pairwise = pd.DataFrame(rows, columns=['model', 'accuracy']).assign(accuracy=lambda d: d['accuracy'].round(4))\n",
    "    overall_pairwise['lift_vs_stage_a'] = (overall_pairwise['accuracy'] - baseline_mean).round(4)\n",
    "    display(overall_pairwise)\n",
    "    top_pairwise = pairwise_summary.sort_values('lift_combined_vs_baseline', ascending=False).head(10) if 'lift_combined_vs_baseline' in pairwise_summary else pd.DataFrame()\n",
    "    bottom_pairwise = pairwise_summary.sort_values('lift_combined_vs_baseline', ascending=True).head(10) if 'lift_combined_vs_baseline' in pairwise_summary else pd.DataFrame()\n",
    "    if not top_pairwise.empty:\n",
    "        print('Top subreddit buckets by combined-model lift (min pairs threshold applied earlier):')\n",
    "        display(top_pairwise[['subreddit', 'pairs', 'baseline_acc', 'combined_acc', 'lift_combined_vs_baseline']])\n",
    "    if not bottom_pairwise.empty:\n",
    "        print('Bottom subreddit buckets by combined-model lift:')\n",
    "        display(bottom_pairwise[['subreddit', 'pairs', 'baseline_acc', 'combined_acc', 'lift_combined_vs_baseline']])\n",
    "    if 'lift_combined_centered_vs_baseline' in pairwise_summary:\n",
    "        top_centered = pairwise_summary.sort_values('lift_combined_centered_vs_baseline', ascending=False).head(10)\n",
    "        bottom_centered = pairwise_summary.sort_values('lift_combined_centered_vs_baseline', ascending=True).head(10)\n",
    "        print('Top subreddit buckets by centered-model lift:')\n",
    "        display(top_centered[['subreddit', 'pairs', 'baseline_acc', 'combined_centered_acc', 'lift_combined_centered_vs_baseline']])\n",
    "        print('Bottom subreddit buckets by centered-model lift:')\n",
    "        display(bottom_centered[['subreddit', 'pairs', 'baseline_acc', 'combined_centered_acc', 'lift_combined_centered_vs_baseline']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef70273",
   "metadata": {},
   "source": [
    "## Success Criteria Check\n",
    "The proposal’s success bar is ≥60% pairwise accuracy while preserving calibration. The cell below consolidates the key metrics from Stage A/B and the pairwise evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23808d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_accuracy = 0.60\n",
    "stage_metrics_lookup = {}\n",
    "if 'stage_summary' in globals():\n",
    "    stage_metrics_lookup = stage_summary.set_index('metric')['value'].to_dict()\n",
    "\n",
    "report_rows = []\n",
    "for label, metric_key in [\n",
    "    (\"Stage A RMSE (log space)\", 'Stage A RMSE (log space)'),\n",
    "    (\"Stage B RMSE (log space)\", 'Stage B RMSE (log space)'),\n",
    "    (\"Stage A residual std\", 'Residual std (Stage A)'),\n",
    "    (\"Stage B residual std\", 'Residual std (Stage B)')\n",
    "]:\n",
    "    value = stage_metrics_lookup.get(metric_key)\n",
    "    if value is not None:\n",
    "        report_rows.append((label, round(float(value), 4)))\n",
    "\n",
    "pairwise_rows = []\n",
    "if 'overall_pairwise' in globals():\n",
    "    pairwise_rows = [(row['model'], row['accuracy']) for _, row in overall_pairwise.iterrows()]\n",
    "elif 'pairwise_filtered' in globals() and not pairwise_filtered.empty:\n",
    "    baseline_mean = pairwise_filtered['baseline_correct'].mean()\n",
    "    pairwise_rows.append(('Stage A baseline', baseline_mean))\n",
    "    if 'combined_correct' in pairwise_filtered:\n",
    "        pairwise_rows.append(('Stage A + Stage B (OLS)', pairwise_filtered['combined_correct'].mean()))\n",
    "    if 'combined_en_correct' in pairwise_filtered:\n",
    "        pairwise_rows.append(('Stage A + Stage B (Elastic Net)', pairwise_filtered['combined_en_correct'].mean()))\n",
    "    if 'combined_lgb_correct' in pairwise_filtered:\n",
    "        pairwise_rows.append(('Stage A + Stage B (LightGBM)', pairwise_filtered['combined_lgb_correct'].mean()))\n",
    "\n",
    "if report_rows:\n",
    "    print(\"Stage-level metrics:\")\n",
    "    display(pd.DataFrame(report_rows, columns=['metric', 'value']))\n",
    "else:\n",
    "    print(\"Stage metrics unavailable; ensure diagnostics cell executed.\")\n",
    "\n",
    "if pairwise_rows:\n",
    "    pairwise_table = pd.DataFrame(pairwise_rows, columns=['model', 'pairwise_accuracy']).assign(pairwise_accuracy=lambda d: d['pairwise_accuracy'].round(4))\n",
    "    pairwise_table['meets_target'] = pairwise_table['pairwise_accuracy'] >= target_accuracy\n",
    "    print(f\"Pairwise accuracy vs. {target_accuracy:.0%} target:\")\n",
    "    display(pairwise_table)\n",
    "    best_accuracy = pairwise_table['pairwise_accuracy'].max()\n",
    "    print(f\"Best observed pairwise accuracy: {best_accuracy:.3f} ({'passes' if best_accuracy >= target_accuracy else 'below'} target)\")\n",
    "else:\n",
    "    print(\"Pairwise evaluation unavailable; rerun pairwise cells if needed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221e122a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save key outputs\n",
    "export_cols = []\n",
    "for col in ['post_id', 'platform', 'subreddit', 'title']:\n",
    "    if col in df.columns and col not in export_cols:\n",
    "        export_cols.append(col)\n",
    "for col in [OUTCOME_COL, EARLY_COL]:\n",
    "    if col in df.columns and col not in export_cols:\n",
    "        export_cols.append(col)\n",
    "for col in ALT_EARLY_COLS:\n",
    "    if col in df.columns and col not in export_cols:\n",
    "        export_cols.append(col)\n",
    "export_cols.extend([col for col in ['y', 'yhat_A', 'R', 'title_lift_component'] if col in df.columns and col not in export_cols])\n",
    "export_cols.extend([col for col in TITLE_FEATURES if col in df.columns and col not in export_cols])\n",
    "out_df = df[export_cols].copy()\n",
    "out_path = OUTPUT_DIR / 'stage_model_outputs.parquet'\n",
    "out_df.to_parquet(out_path, index=False)\n",
    "print('Wrote:', out_path, 'with', out_df.shape[0], 'rows and', out_df.shape[1], 'columns')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
